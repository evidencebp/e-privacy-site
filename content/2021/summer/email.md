Template: event
XStatus: draft
Title: Lasciateci la faccia
Date: 2021-03-15 00:01:00
slug: e-privacy-XXIX-email      
Category: 2021
lang: it
Num: XXIX
Year: 2021
City: RETE
Where: Videoconferenza & Streaming
When: 21-22 maggio
Image: e-privacy-XXIX
Season: summer
Slogan: <i>"I popoli non dovrebbero temere i propri governi: sono i governi che dovrebbero temere i propri popoli."</i><br/><b>V (da John Basil Barnhill)</b>
previd: 2020W
prev: e-privacy-XXVIII
nextid:
next:
Organizzatori: pws, hermes
Collaboratori: bba
Sponsor: cgt,sikurezza.org,sepel,ush,whistleblowingsolutions
Patrocini:
MediaPartner: infomedia,aneddotica
css: .title-XXIX { font: 25px arial, sans-serif; text-align: center; }   .subtitle-XXIX { font: 18px arial, sans-serif; text-align: center; }

###e-privacy 2021 - summer edition

Il ** 21 e 22 maggio 2021 ** ONLINE  si svolgerà **e-privacy 2021
_summer edition_**.

Il tema guida della XXIX edizione di e-privacy è:

<div class="title-XXIX">«Lasciateci la faccia»</div>
<div class="subtitle-XXIX">L'identificazione ed controllo biometrico di massa sono incompatibili con una democrazia rispettosa dei diritti umani?</div>
<br/>

###Iscrizioni

** La partecipazione al convegno è libera e gratuita  **


<!--
<div class="linkbutton"><a class="linkbutton"  href="http://lists.xed.it/ep2019-registration-form">Iscriviti!</a></div>
-->

### <a name="programma"></a>Programma del Convegno


#### <a name="vep"></a>Venerdì 21 maggio 2021 - mattina

* Chairman: <a href="/e-privacy-XXIX-relatori.html#calamari">Marco Calamari (Progetto Winston Smith)</a>

**Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo**
------- | --- | ------- 
10:00|15|<span class='talk'><em>*Apertura lavori*: "Lasciateci la faccia"</em></span>
10:15|35|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#tiani">Vincenzo Tiani (Hermes Center for Transparency and Digital Human Rights)</a><br/><em><a name='1m01'></a><a href="/e-privacy-XXIX-interventi.html#tiani">Riconoscimento facciale: la posizione europea</a></em></span>
10:50|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#giorio">Diego Giorio (Comune di Villanova Canavese / Sepel Editrice)</a><br/><em><a name='1m02'></a><a href="/e-privacy-XXIX-interventi.html#giorio">Oltre il riconoscimento facciale</a></em></span>
11:15|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#fedozzi">Mariangela Fedozzi (Libero Professionista)</a><br/><em><a name='1m03'></a><a href="/e-privacy-XXIX-interventi.html#fedozzi">“LA PRIVACY NON MI INTERESSA PERCHE’ NON HO NULLA DA NASCONDERE”</a></em></span>
11:40|35|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#stringhi">Elisabetta Stringhi (Università degli Studi di Milano)</a>, <a href="/e-privacy-XXIX-relatori.html#bonavita">Simone Bonavita (Information Society Law Center)</a> e <a href="/e-privacy-XXIX-relatori.html#cortina">Alessandro Cortina (Perani Pozzi Associati)</a><br/><em><a name='1m04'></a><a href="/e-privacy-XXIX-interventi.html#stringhi">Intelligenza (o Giustizia) Artificiale? Limiti e criticità di una tecnologia ancora troppo umana</a></em></span>
12:15|60|<span class='talk'>Modera: <a href="/e-privacy-XXIX-relatori.html#calamari">Marco Calamari (Progetto Winston Smith)</a><br/>Partecipano: <a href="/e-privacy-XXIX-relatori.html#senor">Monica Senor </a>, <a href="/e-privacy-XXIX-relatori.html#gallus">Giovanni Battista Gallus (Circolo dei Giuristi Telematici, Nexa Center)</a>, <a href="/e-privacy-XXIX-relatori.html#zurloni">Luca Zorloni (Wired)</a> e <a href="/e-privacy-XXIX-relatori.html#faffa">Raffaele Angius (Wired)</a><br/><em><a name='1m05'></a>Tavola Rotonda: <a href="/e-privacy-XXIX-interventi.html#tavola1">«Lasciateci la Faccia!»</a></em></span>
13:15||<span class='talk'><em>Chiusura lavori</em></span>

#### <a name="vep"></a>Venerdì 21 maggio 2021 - pomeriggio

* Chairman: <a href="/e-privacy-XXIX-relatori.html#giorio">Diego Giorio (Comune di Villanova Canavese / Sepel Editrice)</a>

**Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo**
------- | --- | ------- 
15:00|5|<span class='talk'><em>Apertura lavori</em></span>
15:05|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#longo">Alessandro Longo (Agendadigitale.eu)</a><br/><em><a name='1p01'></a><a href="/e-privacy-XXIX-interventi.html#longo">Intelligenza artificiale, le sfide privacy alla luce del regolamento della Commissione europea</a></em></span>
15:30|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#spataro">Valentino Spataro (IusOnDemand srl)</a><br/><em><a name='1p02'></a><a href="/e-privacy-XXIX-interventi.html#spataro">La gestione concreta delle password private contro l'indispensabilità dei riconoscimenti biometrici pubblici</a></em></span>
15:55|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#zugnaz">Efrem Zugnaz (the Webprepping Initiative)</a><br/><em><a name='1p03'></a><a href="/e-privacy-XXIX-interventi.html#zugnaz">LA GUERRA PER L'ATTENZIONE INIZIATA E'</a></em></span>
16:20|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#berto">Rebecca Berto </a><br/><em><a name='1p04'></a><a href="/e-privacy-XXIX-interventi.html#berto">Le tecnologie ed i dati linguistici – quadro normativo</a></em></span>
16:45|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#gallus">Giovanni Battista Gallus (Circolo dei Giuristi Telematici e Nexa Center)</a><br/><em><a name='1p05'></a><a href="/e-privacy-XXIX-interventi.html#gallus">Dacci la tua faccia, siamo la pubblica amministrazione!</a></em></span>
17:10|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#vieri">Giovambattista Vieri (ENT SRL)</a><br/><em><a name='1p06'></a><a href="/e-privacy-XXIX-interventi.html#vieri">social leak: il bello il brutto e il cattivo. </a></em></span>
17:35|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#blengino">Carlo Blengino </a><br/><em><a name='1p07'></a><a href="/e-privacy-XXIX-interventi.html#blengino">Dal libero convincimento del Giudice alla prova degli algoritmi: la difesa tra byte e processi decisionali automatizzati</a></em></span>
18:00|35|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#romano">Salvatore  Romano (Tracking Exposed)</a><br/><em><a name='1p08'></a><a href="/e-privacy-XXIX-interventi.html#romano">Due esempi di bias algoritmici: la polarizzazione su Youtube e l'eteronomartività su Pornhub.</a></em></span>
18:35|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#surbone">Andrea Surbone (The Jus Semper Global Alliance)</a><br/><em><a name='1p09'></a><a href="/e-privacy-XXIX-interventi.html#surbone">Democrazia, Condorsismo e Partecipazione Popolare</a></em></span>
19:00|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#carletti">Fabio Carletti (Lejot opensource tecnology)</a><br/><em><a name='1p10'></a><a href="/e-privacy-XXIX-interventi.html#carletti">Analysis app. sms/voip for cellular - privacy by design</a></em></span>
19:25||<span class='talk'><em>Chiusura lavori prima giornata</em></span>

#### <a name="sam"></a>Sabato 22 maggio 2021 - mattina

* Chairman: <a href="/e-privacy-XXIX-relatori.html#somma">Emmanuele Somma (Progetto Winston Smith)</a>

 **Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo** 
------- | --- | ------- 
10:00|5|<span class='talk'><em>*Apertura lavori*</em></span>
10:05|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#lopez">Ugo Lopez (Associazione Blue Lighthouse - Edizioni e Formazione)</a><br/><em><a name='2m01'></a><a href="/e-privacy-XXIX-interventi.html#lopez">Schrems II e privacy: cosa succede nel cloud SaaS</a></em></span>
10:30|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#beltrami">Giulio Beltrami (Ecologia dei Sistemi Informativi)</a><br/><em><a name='2m02'></a><a href="/e-privacy-XXIX-interventi.html#beltrami">aPrivacy in HoloCity</a></em></span>
10:55|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#bianchini">Filippo Bianchini (Studio Legale Bianchini)</a><br/><em><a name='2m03'></a><a href="/e-privacy-XXIX-interventi.html#bianchini">Riconoscimento facciale: considerazioni sui diritti fondamentali nel contesto dell'applicazione della legge </a></em></span>
11:20|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#reviglio">Urbano Reviglio (Università di Milano)</a><br/><em><a name='2m04'></a><a href="/e-privacy-XXIX-interventi.html#reviglio">Il Ruolo dei Data Brokers nel Capitalismo della Sorveglianza</a></em></span>
11:45|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#zanoni">Gabriele Zanoni </a><br/><em><a name='2m05'></a><a href="/e-privacy-XXIX-interventi.html#zanoni">Internet of Behaviors</a></em></span>
12:10|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#priolo">Enrica  Priolo (Bonadio Priolo LTF )</a><br/><em><a name='2m06'></a><a href="/e-privacy-XXIX-interventi.html#priolo">La spirale del silenzio fa bene ai diritti umani?</a></em></span>
12:35|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#vendrame">Tobia Vendrame (Uniroma1)</a><br/><em><a name='2m07'></a><a href="/e-privacy-XXIX-interventi.html#vendrame">Antibot Systems</a></em></span>
13:00|25|<span class='talk'><a href="/e-privacy-XXIX-relatori.html#reale">Roberto Reale (Eutopian)</a> e <a href="/e-privacy-XXIX-relatori.html#huyskes">Diletta Huyskes (Privacy Network)</a><br/><em><a name='2m08'></a><a href="/e-privacy-XXIX-interventi.html#reale">Verso una governance europea dell'AI</a></em></span>
13:25||<span class='talk'><em>*Chiusura*</em></span>


## <a name="talks"></a>Gli interventi

#### <a name="beltrami"></a> aPrivacy in HoloCity<a href="/e-privacy-XXIX-programma.html#2m02">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#beltrami">Giulio Beltrami (Ecologia dei Sistemi Informativi)</a>*

La furbizia con cui i virus si propagano, nello spazio e nel tempo, sfruttando la dinamica delle popolazioni, suggerisce di snellire e decongestionare le nostre organizzazioni, per fronteggiare tali e tanti “cigni neri”, adottando il paradigma “olonico-virtuale” per una SmartCity rinominata HoloCity, in cui “olarchia” organizzativa e “olotopia” territoriale favoriscano comunità locali, di vita e lavoro, con un modello di “villaggi globalmente connessi”, caratterizzato da regole flessibili di confinamento e migrazione di risorse, umane e materiali, fra organizzazioni sociali, politiche e imprenditoriali, alternativo al famigerato “villaggio globale”, senza regole e confini.
A questo scopo tali risorse devono essere sistematicamente identificate, assegnate a qualche organizzazione e localizzate, in modo sicuro e riservato, tramite il loro “gemello digitale”,  applicando l’approccio algoritmico ad una privacy (a-privacy) che garantisca:

- Pubblico dominio (apertura) degli algoritmi adottati.
- Identificazione legale degli agenti.
- Completezza e simmetria di rilevazione e registrazione dei fatti, anche sensibili.
- Segreto professionale in cassaforte, come per confessori, avvocati, medici, ecc..
- Regole d’accesso rigorose, per motivazione e autorità.
- Rilevazione e sanzione automatica (con eccezione umana) degli abusi.
- Adozione dell’intelligenza artificiale (con prudenza).

con la presunzione che l’elaborazione di codici digitali sia meglio dell’interpretazione umana di  legislazioni tradizionali.



#### <a name="berto"></a> Le tecnologie ed i dati linguistici – quadro normativo<a href="/e-privacy-XXIX-programma.html#1p04">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#berto">Rebecca Berto </a>*

Nell’anno di celebrazione dei 700 anni dalla morte di Dante, si ricorda come egli collocò il re Nimrod nel pozzo dei giganti perché colpevole di aver sfidato la divinità (Inferno canto XXXI, 51-81): Dante illustrò l’impresa del re fra gli esempi di superbia (Purgatorio Canto XII, 34-36).
Naturalmente si possono leggere tali versi in più modi: la storia del re Nimrod e della torre di Babele ricorda di non avere una sconfinata fiducia nella tecnologia, la quale si prefigge di consentire all’uomo di superare confini naturali, culturali, giuridici.

Oggigiorno le tecnologie del linguaggio hanno numerose applicazioni: dai classici motori di ricerca, al marketing digitale e ai servizi digitali per la salute, per citare alcuni esempi. Le tecnologie del linguaggio sono un settore chiave dell’economia digitale. Il Slator 2020 Language Industry Market stima per il 2022 un volume economico pari a 25,3 miliardi. 

Eppure i dati linguistici sono essenziali per lo sviluppo di tali tecnologie, come per esempio allenare intelligenze artificiali o molto più semplicemente esercitare traduttori automatici. A parte il lessico e la grammatica di ogni lingua, ogni singolo individuo ha un modo del tutto personale di esprimersi e di comunicare, frutto anche per esempio dell’influenza dell’ambiente in cui vive, della propria professione o del livello culturale.

Qual’è la base giuridica per poter allenare per esempio un’intelligenza artificiale con dati linguistici? Ed è possibile trattare la lingua o meglio i dati linguistici creati da ogni singolo individuo, come un dato personale, ai sensi del GDPR?
Scopo dell’intervento è evidenziare come la normativa vigente non disciplini questo aspetto.



#### <a name="bianchini"></a> Riconoscimento facciale: considerazioni sui diritti fondamentali nel contesto dell'applicazione della legge <a href="/e-privacy-XXIX-programma.html#2m03">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#bianchini">Filippo Bianchini (Studio Legale Bianchini)</a>*

Le tecnologie di riconoscimento facciale permettono di confrontare immagini facciali digitali per determinare se sono della stessa persona. Il confronto di filmati ottenuti da telecamere con le immagini nei database è definito "tecnologia di riconoscimento facciale dal vivo". Gli esempi di autorità nazionali preposte all'applicazione della legge nell'UE che utilizzano tale tecnologia sono scarsi, anche se in molti ne stanno testando il potenziale. La relazione intende esaminare le implicazioni per i diritti fondamentali, concentrandosi sul suo uso per l'applicazione della legge
Il GDPR riconosce come "dati sensibili" le immagini facciali delle persone, che sono una forma di dato biometrico. Anche se l'accuratezza delle corrispondenze stia migliorando, il rischio di errori rimane reale, in particolare per alcuni gruppi di minoranze. Inoltre, le persone le cui immagini vengono catturate ed elaborate potrebbero non sapere che questo sta accadendo - e quindi non possono contestare possibili abusi. La relazione analizza queste e altre sfide per i diritti fondamentali che sono innescate quando le autorità pubbliche impiegano tali tecnologie e presenta brevemente i passi da compiere per evitare violazioni dei diritti umani.


#### <a name="blengino"></a> Dal libero convincimento del Giudice alla prova degli algoritmi: la difesa tra byte e processi decisionali automatizzati<a href="/e-privacy-XXIX-programma.html#1p07">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#blengino">Carlo Blengino </a>*

Più che una riflessione "alta" sull'impiego della '"AI" nei tribunali, una modesta testimonianza di come la digitalizzazione delle nostre vite e l'informatizzazione del processo penale abbia sovvertito e minato alcuni fondamenti del processo, dalla parità tra accusa e difesa sino al principio del libero convincimento del giudice, là dove il dubbio non è più ammesso ne contra, né pro reo (abstract mooolto provvisorio ..............................................................................).  


#### <a name="carletti"></a> Analysis app. sms/voip for cellular - privacy by design<a href="/e-privacy-XXIX-programma.html#1p10">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#carletti">Fabio Carletti (Lejot opensource tecnology)</a>*

Vorrei analizzare le app.per cellulari come alcuni esempi signal, telegram witckrMe, ed altre tra le più usate nei contesti diversi di segretezza, differenza e punti di forza come sceglierne per un giusto utilizzo in base all'uso cosa è opensource e cosa solo in parte, punti di forza delle applicazioni che possono essere installate su un cellulare per trasferire messaggi, video o chiamate. Si analizzeranno come lavorano i server cosa sbandierano i produttori e di che nazionalità sono le leggi in vigore dove tengono i server e il modus operandi di sviluppo. 


#### <a name="fedozzi"></a> “LA PRIVACY NON MI INTERESSA PERCHE’ NON HO NULLA DA NASCONDERE”<a href="/e-privacy-XXIX-programma.html#1m03">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#fedozzi">Mariangela Fedozzi (Libero Professionista)</a>*

“LA PRIVACY NON MI INTERESSA PERCHE’ NON HO NULLA DA NASCONDERE”
Questa è un’affermazione che sento dire spesso quando mi reco presso le aziende che seguo come Privacy Manager o D.P.O. durante la formazione di Personale e Management in ambito privacy e data protection. 
Mentre riflettevo sul focus di questo elaborato pensavo a quanto mi piacerebbe disquisire di dati biometrici, smart cities, I.O.T (Internet of Things), riconoscimento facciale e via dicendo… Ma se non sono chiari i concetti fondamentali (e secondo la mia esperienza la maggior parte delle persone non conosce l’argomento) come possiamo addentrarci in sistemi così complessi?
In Primis, qual è la differenza fra privacy e protezione dati? Potrebbero sembrare sinonimi, in realtà sono due cose molto diverse e distinte ma collegate fra loro.
La prima fa riferimento al diritto alla riservatezza delle informazioni personali e della propria vita privata. La privacy tutela la sfera intima del singolo individuo e serve ad impedire che determinate informazioni vengano divulgate in assenza di specifiche autorizzazioni o quando vogliamo delimitare uno spazio personale che non desideriamo venga oltrepassato da sconosciuti. 
La protezione dei dati personali, invece, è un sistema di trattamento degli stessi che identifica direttamente o indirettamente una persona. Nella sua definizione oltre al principio di riservatezza, troviamo quello della disponibilità e dell’integrità dei dati personali. 
Mentre la privacy è uno strumento per allontanare sguardi indesiderati, la protezione dei dati personali mette al centro la persona con riferimento ai suoi dati perché questi costituiscono un’identità. 
Per tornare al titolo della relazione, citando Edward Snowden “Affermare che la privacy non ci interessa perché non abbiamo nulla da nascondere è un po' come affermare che la libertà di parola non ci interessa perché non abbiamo nulla da dire. Occorre fargli capire che stanno fraintendendo il concetto fondamentale dei diritti umani. Non serve giustificare il motivo per cui si ha "bisogno" di un diritto: il carico della giustificazione ricade su chi cerca di infrangere quel determinato diritto. Ma anche se fosse, non puoi cedere i diritti altrui perché a te non sono utili."
Faccio spesso ai miei interlocutori due domande: 
Accetteresti mai di farti visitare dal medico con la porta aperta? Se la risposta è no, il concetto di tutela alla riservatezza è chiaro. 
E ancora: 
mi confideresti le password di tutti i tuoi account e non solo di quello «ufficiale e rispettabile» che utilizzi per lavoro, ma di tutti quelli che possiedi, per permettermi di scandagliare, verificare e curiosare su tutto ciò che fai on line, leggere quello che voglio e pubblicare tutto ciò che troverò interessante? Dopotutto se non hai nulla da nascondere… 
Ad entrambe queste domande mi è sempre stato risposto “NO” e questo perché ogni essere umano istintivamente comprende la profonda importanza della privacy, soprattutto chi la nega. Il mio compito come DPO, Privacy manager e professionista della protezione dati è divulgare il verbo, insegnare alle persone come avvalersi di un loro diritto fondamentale e come tutelare loro stessi e le persone a cui vogliono bene. Bisogna innamorarsi della privacy e della protezione dati personali perché oggi non c'è nulla che ci rappresenti di più!



#### <a name="gallus"></a> Dacci la tua faccia, siamo la pubblica amministrazione!<a href="/e-privacy-XXIX-programma.html#1p05">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#gallus">Giovanni Battista Gallus (Circolo dei Giuristi Telematici e Nexa Center)</a>*

Videosorveglianza e biometria sembravano essere diventate un binomio inscindibile per una "smart" city che si rispetti. Negli ultimi tempi, fortunatamente, si sono moltiplicate le iniziative (anche legislative) volte a evitare i maggiori rischi connessi a queste tecnologie, particolarmente invasive. Il talk si propone di analizzare le principali criticità  e i più recenti sviluppi dell'utilizzo delle tecniche di identificazione biometrica da parte delle pubbliche amministrazioni, per finalità diverse da quelle di polizia e di indagine.


#### <a name="giorio"></a> Oltre il riconoscimento facciale<a href="/e-privacy-XXIX-programma.html#1m02">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#giorio">Diego Giorio (Comune di Villanova Canavese / Sepel Editrice)</a>*

Oggi ci sono telecamere ovunque, legali o meno che siano. Fin quando non sono in rete e si limitano a registrare i movimenti si tratta di un problema relativamente limitato, dato che, di solito, vengono esaminate solo in caso di problemi. Ma se dovessero essere messe in rete - ufficiale o meno - e se dovessero essere associate a sistemi di riconoscimento facciale verremmo di fatto pedinati in ogni spostamento. Ma se già questo può spaventare, pensiamo a cosa accadrebbe se oltre al riconoscimento facciale venissero associate ad un riconoscimento dell'umore e dei sentimenti. Certo, forse si potrebbe evitare che un pilota di linea si suicidi portandosi dietro i passeggeri, ma penso che i problemi ed i rischi per la libertà e la democrazia supererebbero di gran lunga i vantaggi.


#### <a name="longo"></a> Intelligenza artificiale, le sfide privacy alla luce del regolamento della Commissione europea<a href="/e-privacy-XXIX-programma.html#1p01">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#longo">Alessandro Longo (Agendadigitale.eu)</a>*

A fine aprile la Commissione europea presenta il primo regolamento sull'AI, complementare alla normativa GDPR, che nei confronti di big data e AI cominciava a mostrare limiti. Vediamo gli impatti dell'AI sulla privacy (sorveglianza di massa, profilazione con discriminazione a danno soprattutto di minoranze e gruppi sociali deboli) e gli strumenti normativi presenti e auspicabili, nel GDPR e nel regolamento della Commissione. Un tema affrontato dal libro scritto da me e Guido Scorza per Mondadori Education e rivolto alle università


#### <a name="lopez"></a> Schrems II e privacy: cosa succede nel cloud SaaS<a href="/e-privacy-XXIX-programma.html#2m01">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#lopez">Ugo Lopez (Associazione Blue Lighthouse - Edizioni e Formazione)</a>*

Lo scorso anno, in piena pandemia, la sentenza CGUE denominata "Schrems II" ha cambiato completamente le regole del gioco in merito a privacy e GDPR sulle piattaforme cloud SaaS utilizzate in Europa ma appartenenti a multinazionali americane. Il talk intende ripercorrere brevemente l'excursus storico, partendo dal primo ricorso dell'attivista austriaco Maximilian Schrems, per poi analizzare brevemente gli effetti che quest'ultima sentenza ha avuto e sta avendo sulle principali piattafome cloud SaaS utilizzate in Italia per DaD, DDI e smart working


#### <a name="priolo"></a> La spirale del silenzio fa bene ai diritti umani?<a href="/e-privacy-XXIX-programma.html#2m06">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#priolo">Enrica  Priolo (Bonadio Priolo LTF )</a>*

Analizzerò l'effetto prodotto dalla consapevolezza di essere tracciati nell'impianto dei diritti fondamentali della persona. Mi chiederò, in particolare, se l'autocensura possa essere vista come una soluzione al problema "sorveglianza di massa" oppure se costituisca solamente un fallimento del progresso tecnologico. Indagherò su possibili rimedi al tracciamento massiccio e dedicherò un focus al riconoscimento facciale e al suo rapporto con le libertà di  manifestazione del pensiero, di circolazione e di uguaglianza.  


#### <a name="reale"></a> Verso una governance europea dell'AI<a href="/e-privacy-XXIX-programma.html#2m08">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#reale">Roberto Reale (Eutopian)</a> e <a href="/e-privacy-XXIX-relatori.html#huyskes">Diletta Huyskes (Privacy Network)</a>*

Il nuovo Regolamento europeo sull'intelligenza artificiale, la cui versione definitiva è stata resa pubblica il 21 aprile 2021, rappresenta il naturale complemento al GDPR. Le limitazioni stavolta però non riguardano direttamente i dati personali ed il loro trattamento, bensì gli algoritmi e le applicazioni considerate "ad alto rischio". Alcune tecnologie (incluse quelle per la sorveglianza di massa) saranno vietate tout court (almeno sulla carta), altre potranno essere impiegate soltanto a patto che vengano soddisfatti determinati criteri sulla qualità dei dataset (assenza di bias) e sulla "filiera". Al di là di alcune lacune del Regolamento, la sfida (come per il GDPR) sarà impedire che abbiano priorità aspetti puramente formali e che lo sforzo di tracciare una via europea all'intelligenza artificiale sia occasione non soltanto di tutela ma anche di investimenti.


#### <a name="reviglio"></a> Il Ruolo dei Data Brokers nel Capitalismo della Sorveglianza<a href="/e-privacy-XXIX-programma.html#2m04">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#reviglio">Urbano Reviglio (Università di Milano)</a>*

I data brokers sono attori fondamentali del capitalismo della sorveglianza poiché si impegnano nello scambio e inferenza di dati e informazioni personali. E' noto che le loro tecniche di raccolta e analisi dei dati e i numerosi servizi che offrono potrebbero comportare violazioni dei diritti umani. Tuttavia, l'industria dei data brokers rimane ancora un soggetto poco studiato e poco regolamentato. La letteratura accademica è ancora molto limitata. Inoltre, su entrambe le sponde dell'Atlantico, non esiste ancora un chiaro programma normativo. La relazione si propone di offrire una revisione critica interdisciplinare della letteratura più recente. L'efficacia della regolamentazione sia negli Stati Uniti che nell'UE è infatti profondamente discutibile. A causa di tecniche sempre più sofisticate, i data brokers consentono la dataficazione e la persistenza potenzialmente infinita dei dati personali nel cyberspazio. I danni involontari e indesiderabili derivanti dall'attività di questi intermediari di dati sono intrecciati con le basi del capitalismo della sorveglianza. I social media stessi sono pericolosamente legati a tali soggetti. Per essere socialmente sostenibile, l'industria del data brokers avrebbe bisogno non di soluzioni palliative e tolleranti ma di riforme radicali, globali e sistemiche che siano in grado di cambiare gli incentivi economici per allinearli con l'interesse dei cittadini, prima ancora che dei consumatori. La conseguenza più ovvia è che tali soluzioni danneggerebbero il profitto e la crescita di un settore ormai assai potente, opaco e pervasivo. Pertanto, si vuole discutere quali sarebbero le soluzioni più efficaci che si possono intraprendere.


#### <a name="romano"></a> Due esempi di bias algoritmici: la polarizzazione su Youtube e l'eteronomartività su Pornhub.<a href="/e-privacy-XXIX-programma.html#1p08">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#romano">Salvatore  Romano (Tracking Exposed)</a>*

Gli algoritmi sono una soluzione tecnologica al sovraccarico di informazioni: sono tanto potenti quanto necessari per gestire l'overflow di dati che ci raggiunge. Purtroppo, possono anche nascondere l'uso di valutazioni e giudizi basati su bias che hanno un impatto sulla diffusione delle idee e della cultura. Tracking Exposed (tracking.exposed) si occupa da diversi anni di rendere queste "black box" (Pasquale,2016) analizzabili in modo indipendente, sia per i ricercatori/ricercatrici che per gli utenti comuni. In questo intervento discuteremo due degli studi più significativativi che abbiamo condotto sugli algoritmi di raccomandazione di Youtube (https://youtube.tracking.exposed/filtertube/) e Pornhub (Forthcoming). In particolare ci soffermeremo  sull'intersezione tra Echo Chamber e Filter Bubble (Zimmer et al., 2019) e gli effetti sulla polarizzazione (Nikas, 2018) del dibattito nel contesto post-elettorale  americano, presentando una ricerca realizzata in collaborazione con il dipartimento di Media Studies dell'Università di Amsterdam (wiki.digitalmethods.net/). Successivamente  mostreremo i risultati di un recente studio condotto in collaborazione con il progetto Algocount (algocount.org)  dell'Università di Milano sulla struttura della homepage di Pornhub, focalizzandoci su come il design e gli algoritmi di questa piattaforma possono finire per riprodurre l'eteronormatività, nonostante la piattaforma stessa affermi il contrario. 


#### <a name="spataro"></a> La gestione concreta delle password private contro l'indispensabilità dei riconoscimenti biometrici pubblici<a href="/e-privacy-XXIX-programma.html#1p02">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#spataro">Valentino Spataro (IusOnDemand srl)</a>*

La gestione delle password e' oggetto di formazione obbligatoria dei collaboratori ai sensi del GDPR, ma questo lo sappiamo ...

Quello che non sappiamo e' che gestire le password e' semplice.

Piu' difficile condividerle tra pc fisso, portatile, smartphone, tablet ...

E chi gestisce i livelli dei permessi ?

Miracolosamente con il riconoscimento biometrico tutto questo si semplifica, e diventa piu' sicuro. Ma e' proprio cosi' ?

Proviamo a ipotizzare il riconoscimento biometrico nelle imprese e nella P.A. Per scoprire che il Garante ha di recente rivalutato la necessità di minimizzare assolutamente il trattamento di questi dati.

Allora: dati biometrici si' o no ?


#### <a name="stringhi"></a> Intelligenza (o Giustizia) Artificiale? Limiti e criticità di una tecnologia ancora troppo umana<a href="/e-privacy-XXIX-programma.html#1m04">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#stringhi">Elisabetta Stringhi (Università degli Studi di Milano)</a>, <a href="/e-privacy-XXIX-relatori.html#bonavita">Simone Bonavita (Information Society Law Center)</a> e <a href="/e-privacy-XXIX-relatori.html#cortina">Alessandro Cortina (Perani Pozzi Associati)</a>*

Partendo da una rapida rassegna ed analisi di possibili tecniche e "trucchi" per ingannare i sistemi di video-sorveglianza dotati di sistema di riconoscimento facciale tramite il trattamento dei dati personali biometrici, ci interrogheremo sulla correttezza di ricorrere a tali tecnologie, sulle quali non abbiamo ancora un pieno controllo e delle quali non conosciamo effettivamente il funzionamento interno, per finalità di giustizia predittiva, sicurezza nazionale, verifica dell'identità personale. Non si può fare affidamento a tali sistemi come se costituissero una panacea per tutte le problematiche di sicurezza, in quanto forieri di errori, discriminazioni e potenziali ingiustizie. 


#### <a name="surbone"></a> Democrazia, Condorsismo e Partecipazione Popolare<a href="/e-privacy-XXIX-programma.html#1p09">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#surbone">Andrea Surbone (The Jus Semper Global Alliance)</a>*

I cittadini devono tornare a essere demos.
Ma senza un rinnovato assetto istituzionale non sarà possibile.
Anzi, il solco fra la politica e i cittadini diverrà sempre più profondo, fino a farsi voragine.
Con la conseguenza di una sempre più forte richiesta di “uomo forte”, di nocchiere che ci tragga dai marosi.
Siamo di fronte al classico cane che si morde la coda, eppure da una qualche parte è necessario e urgente cominciare.
In gioco c’è la democrazia, intesa come istanze che provengono dal popolo, come partecipazione popolare e come controllo popolare.
Non è più possibile opporsi alla deriva della democrazia, di cui la sorveglianza di massa è una “punta di diamante dell’iceberg”, senza che ognuno di noi assuma il suo compito.
Il saggio che propongo come relazione si può trovare qui: https://www.jussemper.org/Inicio/Recursos/Democracia%20Mejores%20Practicas/Resources/AndreaSurbone-DemocraziaCondorsismoePartecipazionePopolare(italiano).pdf



#### <a name="tiani"></a> Riconoscimento facciale: la posizione europea<a href="/e-privacy-XXIX-programma.html#1m01">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#tiani">Vincenzo Tiani (Hermes Center for Transparency and Digital Human Rights)</a>*

Da tempo si discute in Europa su come e se regolare il riconoscimento facciale. Nel 2019 l'EDPB ha pubblicato delle linee guida sulla video sorveglianza mentre la FRA ha pubblicato la sua analisi dell'impatto dell'adozione di queste tecnologia sui diritti fondamentali. Il 21 Aprile 2021 la Commissione Europea ha da ultimo pubblicato la sua proposta di regolamentazione europea sull'Intelligenza Artificiale che va a toccare anche il tema del riconoscimento facciale. In questo panel faremo il punto sulle indicazioni normative europee già adottate e in corso di discussione su questo tema controverso.


#### <a name="vendrame"></a> Antibot Systems<a href="/e-privacy-XXIX-programma.html#2m07">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#vendrame">Tobia Vendrame (Uniroma1)</a>*

Antibot systems sarà una presentazione che darà alla platea una rappresentazione ad alto livello del comportamento dei bot e dei sistemi
che prevengono il loro utilizzo.
Durante gli ultimi anni entrambi i soggetti in questione (bot e antibot) hanno guadagnato una buona fetta di mercato digitale,
sono infatti nate diverse realtà e soluzioni per la loro gestione, esse però come analizzato dai miei ultimi approfondimenti garatiscono solo
parzialmente l'anonimato e la privacy, nonostante il loro utilizzo non sia direttamente applicato all'utente finale, queste tecniche
in maniera silente estrapolano una grande quantità di dati in maniera silente.


#### <a name="vieri"></a> social leak: il bello il brutto e il cattivo. <a href="/e-privacy-XXIX-programma.html#1p06">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#vieri">Giovambattista Vieri (ENT SRL)</a>*

Tutti sappiamo cosa sia un social network. Sappiamo come nasce, come si sviluppa e come ci avviluppa. Insomma oramai sappiamo tutto dei social. In questa presentazione vedremo che effetti causa una dispersione dei dati in esso contenuti. PEr farlo seguiremo la vita di un social dall'idea a un evento di perdita di dati. E, da quel punto cercheremo di capire gli impatti su singoli, cultura, societa' e imprese anche apparentemente non collegate ad esso. Forse scopriremo che non tutto e' come appare e nemmeno come pensavamo. Forse potremmo scoprire che un social non e' solo un qualcosa utile a coloro che una volta si definivano scioperati, fannulloni e perditempo. Potremmo cominciare a pensare che il tesoro vero potrebbero non sono i dati personali dei singoli e, che la societa' civile dovrebbe poter avere accesso a questi dati.


#### <a name="zanoni"></a> Internet of Behaviors<a href="/e-privacy-XXIX-programma.html#2m05">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#zanoni">Gabriele Zanoni </a>*

Gabriele Zanoni lavora come Senior Strategic Consultant in Mandiant. Il suo ruolo attuale gli permette di lavorare come Trusted Advisor su progetti strategici di cyber security nel settore Enterprise in Italia e in EMEA.

In passato, in qualità di Incident Responder, è stato coinvolto in attività di gestione degli incidenti per la difesa da attacchi e attaccanti State-Sponsored. Ha contribuito alla messa in sicurezza di aziende Enterprise, in Europa e Medio Oriente, in diversi settori come quello governativo, finanziario, delle telecomunicazioni, dei trasporti e non ultimo in quello energetico. 

Ha lavorato come Penetration Tester per la sicurezza di molti istituti bancari Italiani ed esteri e ha coordinato team di sicurezza per il test e la risoluzione di vulnerabilità su sistemi critici.

È appassionato di OSINT (Open Source INTelligence) e di Analisi Forense, e spesso partecipa come relatore a conferenze inerenti questi temi.


#### <a name="zugnaz"></a> LA GUERRA PER L'ATTENZIONE INIZIATA E'<a href="/e-privacy-XXIX-programma.html#1p03">⇧</a>
*<a href="/e-privacy-XXIX-relatori.html#zugnaz">Efrem Zugnaz (the Webprepping Initiative)</a>*

La guerra dell’attenzione ci vede partecipi che lo vogliamo o no. Oggi non è più importante avere un pubblico o avere opinioni, importa solo avere attenzione. Quanto siamo disposti a perdere per l'attenzione. Oggi è tutto relativo. Fermiamoci ancora una volta a pensare e utilizziamo semplici e banali contromisure, poco teniche, molto psicologiche per la nostra resilienza digitale. Poco serve leggere e guardare internet senza campirne il messaggio e discriminare le informazioni. Riflettere insieme per progredire insieme.




## <a name="speakers"></a>I chairman

### <a name='calamari'></a> Marco Calamari (Progetto Winston Smith)

Marco Calamari. Ingegnere, classe 1955, talvolta noto come Cassandra,
a 18 anni dovette decidere se comprarsi una macchina usata od un
pc. Scelse il pc e da allora non si e' ancora completamente ripreso.
Lavora come archeologo di software legacy in una grande
multinazionale, ma e' appassionato di privacy e crittografia in Rete,
dove collabora a progetti di software libero come Freenet, Mixmaster,
Mixminion, Tor & GlobaLaks.

E' il fondatore del Progetto Winston Smith e tra i fondatori
dell'associazione Hermes Centro Studi Trasparenza e Diritti Umani Digitali.  
Dal 2002 organizza il convegno "e-privacy" dedicato alla
privacy in Rete e fuori, ed e' editorialista di "Punto Informatico"
dove pubblica la rubrica settimanale 
<a href="http://punto-informatico.it/cerca.aspx?s=cassandra%20calamari&t=4">"Cassandra Crossing"</a>.

### <a name='giorio'></a>Diego Giorio  (Progetto Winston Smith)

Dopo un'esperienza nell'industria privata, nella ricerca&sviluppo di
una multinazionale di seminconduttori prima, nel marketing e nel web
marketing poi, ho successivamente avuto altre esperienza professionali
prima di approdare alla Pubblica Amministrazione, nei servizi
demografici di un piccolo Comune. Dal 2009 ho iniziato a pubblicare
con SEPEL articoli in varie materie demografiche e di interesse
generale della PA, ho tenuto corsi di formazione per un'Associazione
di settore, dopo avere ottenuto il titolo di formatore dal Ministero
dell'Interno. Fra i vari interessi, la privacy ed il suo impatto sulla
PA, e dal 2012 seguo il convegno e-privacy, sia come uditore che come
relatore.


### <a name='somma'></a>Emmanuele Somma  (Progetto Winston Smith)

Emmanuele Somma è prestato da anni al Progetto Winston Smith,
collabora con il Centro Hermes per la Trasparenza e i Diritti Umani
Digitali ed è militante del Partito Radicale. È giornalista
pubblicista, ha fondato Linux Magazine e dirige "LOGIN, saving the
Internet wealth".

## <a name="speakers"></a>I relatori

#### <a name="faffa"></a> Raffaele Angius (Wired)

Giornalista freelance per La Stampa, Wired e IrpiMedia, specializzato nell’impiego di strumenti informatici per la protezione delle fonti e delle telecomunicazioni.
Dal 2016 si occupa di progetti per la raccolta di segnalazioni anonime su corruzione e criminalità organizzata tra i quali RegeniFiles, la piattaforma de la Repubblica dedicata alla raccolta di informazioni sulle violazioni dei diritti umani in Egitto e sull'omicidio di Giulio Regeni. Come giornalista, realizza principalmente inchieste su crimini informatici, diritti umani digitali e sorveglianza di Stato.
È membro dell’Hermes Center for Transparency and Digital Human Rights, con il quale collabora alla diffusione di strumenti per la protezione del lavoro giornalistico e delle fonti.



#### <a name="beltrami"></a> Giulio Beltrami (Ecologia dei Sistemi Informativi)

Giulio Beltrami è nato a Milano il 23 marzo 1944, ove risiede.

Laureato in [astro]fisica all'Università degli Studi di Milano nel 1969, è stato per 8 anni consulente alla Syntax SpA (Olivetti) nella progettazione e sviluppo di software di sistema.
Per altrettanti anni ha coordinato in Italtel SpA (STET) l'attività di assistenza agli utenti R&S, nell'area dei sistemi distribuiti, dei packages, della telematica e dei servizi "infocenter".
Dal 1985 alla Logos Progetti SpA, software house poi confluita nel Gruppo Olivetti, ha coordinato progetti di ricerca in ambito europeo e lo sviluppo di diverse applicazioni telematiche; quindi ha contribuito al disegno di una linea di prodotti software per banche dati e gestione documentale, che quindi ha promosso, come responsabile aziendale del supporto commerciale e marketing.

Membro delle associazioni informatiche AICA, ClubTI Milano (ex), Informatici senza Frontiere (Italia) e ACM (USA) e partecipe alla Fondazione RCM (Rete Civica di Milano), si è anche interessato agli aspetti sociali delle tecnologie dell'informazione e della comunicazione, senza trascurare fenomeni "tecno-anarchici" e "cyberpunk".

In pensione dal 2002, continua ad occuparsi di informatica, in modo amatoriale; con la ricerca e sviluppo di sistemi di assistenza alle relazioni d'affari, entro comunità in rete, basati su originali architetture informative/cognitive e sulle tecnologie OO, ODBMS, XML e NOSQL di alcuni sponsor, fra cui Software-AG, Sonic Software, Intersystems e Google; i risultati attesi sono una piattaforma applicativa "Community Business Server"​ e una teoria sulla conoscenza/coscienza collettiva emergente dal suo funzionamento in Internet.

Ha usato tale piattaforma nel progetto "condomotico" vincitore del Premio Perotto 2010.

Dal 2011 la piattaforma si è evoluta al cloud​ sulla "Google App Engine", stressando il concetto di collaborazione​, con rivoluzionarie architetture applicative "Hyper-Business"​ e "Hyper-Enterprise".



#### <a name="berto"></a> Rebecca Berto 

Rebecca Berto è attiva come consulente legale in un progetto europeo finanziato anche dalla Commissione Europea. Ha mosso i primi passi lavorativi in ambito legale in uno studio legale della Corte d'Appello di Trento. Poi gli eventi l'hanno portata prima a lavorare per un'azienda a partecipazione pubblica e poi all'interno dell'attuale progetto europeo.
Ha continuato a studiare, specializzandosi in risoluzione internazionale delle dispute commerciali, in altre parole arbitrati commerciali internazionali e dispute internazionali relativi ad investimenti. Per questo motivo procedure come quelle previste dal WTO o ICSID sono conosciute. Se volete chiederle dell'Energy Charter Treaty e della “Saga sull’energia rinnovabile” ve ne parlerà per ore! Nata a Celle, in Germania, vive e lavora in Trentino Alto Adige. Pensa e parla in italiano ed in tedesco, parla e pensa anche in inglese... ogni tanto dice qualche frase in russo, lingua che cerca di studiare di più, fra un’attività ed un’altra. Ha la passione per le scienze naturali, la fisica e le nuove tecnologie.




#### <a name="bianchini"></a> Filippo Bianchini (Studio Legale Bianchini)

L’Avv. Filippo Bianchini, abilitato al patrocinio innanzi alle Giurisdizioni Superiori, si è laureato in Giurisprudenza presso l’Università degli Studi di Perugia; nel 2006 ha fondato lo Studio Legale Bianchini e svolge attività nei settori data protection & privacy, diritto dell’IT e diritto civile, nonché diritto penale. 
Si occupa di gestione della sicurezza delle informazioni e della protezione dei dati personali in qualità di consulente di primarie Società ed Enti e svolge attività di auditing (è Lead Auditor ISO/IEC 27001:2017), di adeguamento al GDPR nonché il ruolo di Data Protection Officer (certificato UNI 11697:2017).
È docente di informatica giuridica per la Scuola Forense “G. Gatti” dell’Ordine degli Avvocati di Perugia e docente del Master universitario di primo livello in “Data protection, Cybersecurity e Digital forensics” organizzato dal Dipartimento di Giurisprudenza dell'Università per gli Studi di Perugia; è, inoltre, relatore in numerosi convegni in materia di data protection e cyber security.
È membro del Cyber Security National Lab, nodo di Perugia e dell’Internet of Things Council, nonché socio del Circolo Giuristi Telematici e dell’Associazione Informatici Professionisti.
Segue l’evoluzione dei fenomeni legati ad internet ed alle nuove tecnologie, con particolare attenzione per gli aspetti legali connessi.



#### <a name="blengino"></a> Carlo Blengino 

Carlo Blengino, avvocato, svolge la professione esclusivamente nel settore penale, in particolare nel settore dei reati colposi, delle responsabilità professionali e del penale dell'economia, con una particolare attenzione alla proprietà intellettuale ed alle criticità legate all'informatica, alle nuove tecnologie ed alla tutela della riservatezza e dei dati personali. Collabora con alcune riviste on-line tra cui Medialaws.eu ed ha pubblicato con Giappichelli Editore, UTET Giuridica, Egea ed Aracne. E' fellow del NEXA Center for Internet & Society del Politecnico di Torino ed ha un blog personale sul quotidiano on-line ilPOST.it.



#### <a name="bonavita"></a> Simone Bonavita (Information Society Law Center)

Simone Bonavita è Professore a contratto in trattamento dei dati sensibili presso l’Università degli Studi di Milano per l’anno accademico 2022/2021, Keystaff del progetto di eccellenza europea Jean Monnet “European Citizens’ online fundamental rights, data governance and cybersecurity in the Information Society: an European legal framework” (#DATAGOV)” e cultore della materia di Informatica Giuridica (Ppof. G. Ziccardi) presso la medesima Università, all’interno della quale svolge oggi attività didattica. Docente dei corsi di perfezionamento in “Data Protection & Data Governance”, “Computer Forensics ed indagini digitali” e “Coding for lawyer & legal Tech” dell’Università degli Studi di Milano, si è formato prima presso l’Università degli Studi di Milano, laureandosi in scienze giuridiche ed in giurisprudenza con tesi specialistiche in materia di privacy e nuove tecnologie e perfezionandosi in indagini digitali. Successivamente presso l’ALMA Mater - Università di Bologna ha conseguito il Master in Diritto delle nuove tecnologie ed Informatica Giuridica ed il Dottorato di ricerca in Diritto delle nuove tecnologie ed Informatica Giuridica (CIRSFID) sotto la guida del prof. G. Sartor. Nel corso del 2017 è stato Visiting all’European University Institute (EUI) di Firenze. Dal 2018 è research all’Information Society Law Center dell’Università degli Studi di Milano. Svolge la propria attività professionale quale Avvocato del foro di Milano presso lo studio Perani Pozzi Associati. La sua attività professionale, principalmente stragiudiziale, si concentra essenzialmente nel settore del diritto delle nuove tecnologie ed in particolare nella data governance. Assiste quotidianamente importati gruppi nazionali ed internazionali, istituti di credito, TELCO, agenzie di comunicazione ed agenzie reputazionali. Presente come relatore a convegni e seminari, è autore di numerose pubblicazioni aventi ad oggetto il diritto delle nuove tecnologie, il trattamento dei dati personali e la responsabilità degli ISP e profili giuridici di comunicazione digitale.



#### <a name="carletti"></a> Fabio Carletti (Lejot opensource tecnology)

Fabio Carletti aka Ryuw, strategic IT consultant, relatore IPA(International Police Association) e docente CLUSIT, noto ai più per questioni legate alla Sicurezza Informatica ha ottenuto importanti apprezzamenti in attività investigative nella informatica forense. 



#### <a name="cortina"></a> Alessandro Cortina (Perani Pozzi Associati)

Laureato con lode in “Sicurezza dei sistemi e delle reti informatica”, con una tesi in materia di cloud computing e Perfezionato in "Criminalità informatica e investigazione digitale" presso l'Università degli Studi di Milano. I miei interessi sono rivolti agli ambiti della protezione e della privatezza dei dati, della privacy, della tutela dei dati personali, della data governance, della compliance e del rapporto tra Diritto e Sicurezza Informatica. Collaboro con lo Studio Perani Pozzi Associati fornendo consulenza per le società in tematiche relative alla sicurezza informatica, alla compliance rispetto alla norme vigenti in tema di privacy e data protection e, inoltre, mi occupo di attività di digital forensics (relazioni tecniche e investigazioni digitali).



#### <a name="fedozzi"></a> Mariangela Fedozzi (Libero Professionista)

La mia professione è Privacy Manager e Responsabile Protezione Dati (o D.P.O.), unico core business della mia attività.
La mia responsabilità principale come D.P.O. è quella di osservare, valutare e organizzare la gestione del trattamento di dati personali (e dunque la loro protezione) all’interno di un’azienda (sia essa pubblica che privata), affinché questi siano trattati nel rispetto delle normative privacy europee e nazionali. Nell’eseguire questi compiti devo considerare debitamente i rischi inerenti al trattamento, tenuto conto della natura, dell’ambito di applicazione, del contesto e delle finalità del medesimo. 
Ho competenze giuridiche, informatiche, di risk management e di analisi dei processi. 
Come Privacy Manager fornisco la consulenza necessaria per progettare, verificare e mantenere un sistema organizzato di gestione dei dati personali, curando l’adozione di un complesso di misure di sicurezza finalizzate alla tutela dei dati che soddisfino i requisiti di legge e assicurino sicurezza e riservatezza.
Svolgo questa attività come libera professionista da 4 anni mentre precedentemente, per molti anni, mi sono occupata anche di privacy presso lo studio legale penale tributario di famiglia quando entrava in vigore il codice privacy italiano D.Lgs 196/2003 in abrogazione alla precedente legge 675/96. 
Ho conseguito un Master Privacy Officer e Consulente della Privacy con attestato di competenza conseguito con TÜV Italia accreditato dal Consiglio Nazionale Forense, Attestato di Qualità in base a Legge 4/2013 rilasciato da Federprivacy oltre ad altri master e seminari per D.P.O. riconosciuti e certificati Tüv Italia.
Sono Socia Federprivacy, Persone&Privacy e A.N.C.IMP Italia



#### <a name="gallus"></a> Giovanni Battista Gallus (Circolo dei Giuristi Telematici, Nexa Center)

Diritto d’autore, diritto penale, tutela della privacy e diritto dell’informatica e delle nuove tecnologie sono le sue principali materie di competenza. Dopo la laurea cum laude in giurisprudenza in Italia si trasferisce in Gran Bretagna per il Master of Laws in Maritime Law e Information Technology Law alla University College London – UCL.. In seguito consegue il titolo di dottore di ricerca. Nel 2009 ottiene lo European Certificate on Cybercrime and Electronic Evidence (ECCE). Iscritto all’Albo degli Avvocati dal 1996, Cassazionista dal 2009, Data Protection officer per diversi enti, collabora con la cattedra di Informatica Giuridica dell’Università di Milano ed è docente al Corso di Perfezionamento in Criminalità informatica e prova digitale, ed al Master DPO del Politecnico di Milano. Fellow del Nexa Center on Internet e Society e dell' Hermes Center for Transparency and Digital Human Rights. Autore di diverse pubblicazioni sui temi citati e relatore nei principali convegni nazionali e internazionali, affianca alla professione attività di formazione, in particolare nel campo del diritto d’autore, del Free software – Open Source, della tutela della privacy, della sicurezza informatica e della digital forensics. Past Presidente del Circolo dei Giuristi Telematici, fondato nel 1998, primo esempio italiano di associazione giuridica telematica, è componente della Commissione Privacy del Consiglio Nazionale Forense,  e membro dell'Advisory Board dell'Osservatorio Droni del Politecnico di Milano.



#### <a name="huyskes"></a> Diletta Huyskes (Privacy Network)

Diletta Huyskes è laureata in Filosofia e ricerca l'impatto sociale dell’IA e delle nuove tecnologie da un punto di vista etico e politico. Alcuni dei suoi ambiti di interesse sono le disuguaglianze tecnologiche, soprattutto di genere, e l'utilizzo di algoritmi e software nei processi decisionali, l’etica dei dati e la sorveglianza. E' la responsabile Advocacy di Privacy Network, associazione nata per tutelare i diritti fondamentali digitali, e giornalista freelance. 



#### <a name="longo"></a> Alessandro Longo (Agendadigitale.eu)

Giornalista professionista, direttore di Agendadigitale.eu, co-autore di Intelligenza Artificiale, impatti sulle nostre vite, società e diritti per Mondadori Education, collaboratore storico di Repubblica e Sole24Ore per questi temi



#### <a name="lopez"></a> Ugo Lopez (Associazione Blue Lighthouse - Edizioni e Formazione)

Docente universitario di informatica forense e sicurezza nelle reti e nei sistemi distribuiti presso Uniba, ingegnere informatico, membro fondatore di ILS Bari, laureando in scienze giuridiche con una tesi sulle differenza tra software libero e Open Source. Certificato LPIC-2, CompTIA Linux+, Microsoft Enterprise Administrator Expert (Microsoft 365), Google Workspace Administrator



#### <a name="priolo"></a> Enrica  Priolo (Bonadio Priolo LTF )

Senior partner dello studio legale Bonadio Priolo LTF, sono avvocata (di estrazione penalista) e formatrice, specializzata in diritti umani e in legal tech. Le mie aree di ricerca sono principalmente la privacy, l'intelligenza Artificiale, i processi decisionali automatizzati e l'ethics by design; il mio approccio al diritto è di tipo filosofico. Sono co-founder dell'associazione Legal Hackers Pisa.



#### <a name="reale"></a> Roberto Reale (Eutopian)

Informatico, policy advisor e manager dell’innovazione con oltre 10 anni di esperienza in progetti di e-government e trasformazione digitale di settori strategici in ambito nazionale e UE (organi parlamentari, finanza pubblica, procurement, infrastrutture critiche, servizi pubblici) e 20 anni di esperienza in sviluppo, progettazione e gestione di piattaforme ICT. Nel quinquennio 2010-14 ha curato progetti di e-government presso il Ministero degli Affari Esteri, nel biennio 2016-18 presso la Camera dei deputati, dal 2018 cura progetti europei in ambito procurement elettronico e fatturazione elettronica presso l’Agenzia per l’Italia digitale.



#### <a name="reviglio"></a> Urbano Reviglio (Università di Milano)

Urbano Reviglio ha appena concluso il suo dottorato LAST-JD ERASMUS MUNDUS in law, science and technology coordinato dall'Università di Bologna focalizzandosi sull'etica, la regolazione e la governance della personalizzazione dei contenuti nei social media. Attualmente è parte del progetto dell'Università di Milano "Algocount" che mira, fra i vari obiettivi, a proporre soluzioni di policy nel contesto degli algoritmi che influenzano l'opinione pubblica.



#### <a name="romano"></a> Salvatore  Romano (Tracking Exposed)

Laureato in Psicologia Sociale all'Università di Padova, si occupa di
Analisi degli algoritmi e dei discorsi di odio sui social media, in
particolare nella sfera politica.
È attualmente membro del collettivo Tracking.Exposed, con il quale
conduce analisi sull'algoritmo di raccomandazione di Youtube e Pornhub.
Si occupa di hate speech online e della sua relazione con la
comunicazione politica, collaborando con la "Rete Nazionale per il
contrasto ai linguaggi e ai fenomeni d'odio" di cui è membro. 



#### <a name="senor"></a> Monica Senor 

Monica Senor è avvocato penalista specializzato in diritto penale delle nuove tecnologie, privacy e data protection. E' fellow di NEXA, il Centro per Internet & Società del Politecnico di Torino, membro della Commissione informatica del COA di Torino, del comitato scientifico dello CSIG (Centro studi di informatica giuridica Ivrea-Torino) e del CSPT (Centro Studi per il Processo Telematico). Collabora con le riviste online Medialaws.eu, IlProcessoTelematico.it e ForumPA.it ed ha pubblicato lavori con Egea, Giappichelli, Springer, UTET Giuridica ed Aracne.



#### <a name="spataro"></a> Valentino Spataro (IusOnDemand srl)

Podcaster, consulente Privacy e sviluppatore informatico, unisco il mondo del diritto all'informatica, divulgandola tramite il podcast Caffe20.it dal 2008. Ho realizzato il comparatore tra lingue del GDPR su Privacykit.it



#### <a name="stringhi"></a> Elisabetta Stringhi (Università degli Studi di Milano)

Elisabetta Stringhi è Dottoressa cum laude in Giurisprudenza con una Tesi in Informatica Giuridica presso l'Università degli Studi di Milano. Attualmente sta svolgendo la pratica forense nell'ambito del diritto delle nuove tecnologie. E' stata Visiting presso l'Institute for Information Law (IViR) di Amsterdam. 



#### <a name="surbone"></a> Andrea Surbone (The Jus Semper Global Alliance)

Andrea Surbone, scrittore, editore ed ex viticoltore.
Ha scritto narrativa con Pulviscolo e dal novembre 2007 redige il "buona settimana", una piccola rubrica di sguardi sul mondo, inviata ogni lunedì via email.
Editore della rivista Nuvole (numeri cartacei dal 16 al 23) e tuttora membro della Redazione (www.nuvole.it). 
Portavoce di una proposta di economia politica (www.propostaneokeynesiana.it).
Promotore di una proposta politica (www.surbone.it/per).




#### <a name="tiani"></a> Vincenzo Tiani (Hermes Center for Transparency and Digital Human Rights)

Vincenzo Tiani è partner della sede di Bruxelles dello studio legale Panetta & Associati, specializzato in  privacy e diritto delle nuove tecnologie, ed è membro del board di Hermes Center. Ha lavorato al Parlamento Europeo e in due organismi internazionali che tutelano i diritti fondamentali online. È professore a contratto di diritti digitali e scrive regolarmente di politiche digitali europee per diverse testate giornalistiche. 



#### <a name="vendrame"></a> Tobia Vendrame (Uniroma1)

Sono uno studente laureando al corso magistrale di cybersecurity presso la Sapienza (Uniroma1), inoltre ho svolto la mia laurea triennale in ingengeria informatica a Padova.
Nel corso degli ultimi anni mi sono dilettato con varie tecniche di reverse engineering, dal quale appunto, nasce la presentazione: Antibot Systems



#### <a name="vieri"></a> Giovambattista Vieri (ENT SRL)

Giovambattista Vieri, son nato nel 1964, sono appassionato di informatica da quando avevo 16 anni e con l'aiuto del saldatore modificavo lo spectrum. Ho poi lavorato nell'industria aerospaziale (project leader) sia su GUI sia su apparati embedded, passando poi a societa' di consulenza e formazione (responsabile gruppo internet), poi a societa' editoriali con ruoli anche inerenti la IT security. Infine imprenditore (molto piccolo) e consulente. Nei ritagli di tempo, scrivo software che poi libero . Son anche molto appassionato di Storia (antica e recente) e sport. Amo la cucina e la buona tavola condita da discussioni interessanti. E dimenticavo che istruisco i computer a ripetere i ns errori. 



#### <a name="zanoni"></a> Gabriele Zanoni 

L’IoB è una combinazione di tre campi: Technology, Data analytics e Behavioral science.
Le aziende imparano sempre di più sulle persone dai device IoT, e questo viene usato per nel campo dell’IoB per influenzare le scelte delle persone.
Nell'IoB l’interconessione tra in dati e il nostro processo decisionale richiede una serie di attenzioni a diversi livelli.



#### <a name="zurloni"></a> Luca Zorloni (Wired)

Responsabile economia e attualità di Wired, impegnato in giornalismo di inchiesta e di approfondimento su temi legati ai rapporti tra tecnologia, business, diritti civili e politici, regole europee e sicurezza informatica. Appassionato di Cina, seguo con attenzione la partita del 5G



#### <a name="zugnaz"></a> Efrem Zugnaz (the Webprepping Initiative)

Efrem Zugnaz, opera nel settore IT da piu' di venticinque anni. Attualmente si occupa PRIVACY in ambito Autostradale. Fondatore dell'iniziative WEBPREPPING che da dieci anni si occupa di survivalismo digitale per la gente comune, la scuola e le istituzioni. Avendo passato molte fasi tecnologiche ora si occupa di portare in maniera gratuita a quanti possibile buone prassi ed informazioni per i cittadini digitali, con lo scopo di alimentare una sfera info-digitale etica e corretta, ma soprattutto psicologicamente ecologica.







### Gli organizzatori

La manifestazione e’ organizzata da:

 - [HERMES](http://logioshermes.org/) \- Centro Studi Trasparenza e Diritti Umani Digitali.
 - [Progetto Winston Smith](http://pws.winstonsmith.org/) è un’associazione senza fini di lucro che si occupa della difesa del diritto alla privacy in Rete e fuori


### Contatti

Per contatti generali e per la
stampa: [eprivacy@winstonsmith.org](mailto:eprivacy@winstonsmith.org),
per i relatori
[cfp-eprivacy@winstonsmith.org](mailto:cfp-eprivacy@winstonsmith.org).

Maggiori informazioni saranno pubblicate sul sito del Convegno non appena
disponibili, all'indirizzo [e-privacy.winstonsmith.org](http://e-privacy.winstonsmith.org).

**Vi aspettiamo**.
