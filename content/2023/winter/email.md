slug: e-privacy-XXXIII-email
Template: event
XStatus: draft
Title: IA: Tecnologia, Etica e Privacy
Date: 2023-09-13 12:05:00
Category: 2023
lang: it
Num: XXXIII
Year: 2023
City: PISA
Where: Pisa & Videoconferenza & Streaming
When: 23-34 novembre
Season: winter
Slogan: <i>"I popoli non dovrebbero temere i propri governi: sono i governi che dovrebbero temere i propri popoli."</i><br/><b>V (da John Basil Barnhill)</b>
previd: 2023W
prev: e-privacy-XXXII
nextid:
next:
Organizzatori: pws, hermes
Collaboratori: 
Patrocini: 
Sponsor: cgt,sikurezza.org,sepel,ush,isgroup
MediaPartner: infomedia,aneddotica,lealternative, hackerjournal
timeline: 20 ottobre | 27 ottobre | 17 novembre
css: .title-XXXI { font: 25px arial, sans-serif; text-align: center; }   .subtitle-XXXI { font: 18px arial, sans-serif; text-align: center; }


###e-privacy 2023 - winter edition

Il ** 23 e 24 novembre 2023 **  a Pisa si svolgerà **e-privacy 2023
_winter edition_**.


<div class="title-XXXIII">«IA: Tecnologia, Etica e Privacy»</div>
<div class="subtitle-XXXIII">un impegnativo viaggio per i prossimi cambiamenti sociali; il dibattito si alterna tra etica e tecnologia, ma non deve trascurare la privacy</div>
<br/>

**Il convegno ha ottenuto il patrocinio dell'Autorità Garante per la protezione dei Dati Personali**.



###Iscrizioni

** La partecipazione al convegno è libera e gratuita  **


### <a name="programma"></a>Programma del Convegno


#### <a name="vep"></a>Giovedì 23 novembre 2023 - mattina

<!-- iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/O5C8u-xpmz0" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe -->

* Modera: <a href="/e-privacy-XXXII-relatori.html#marcoc">Marco2 Calamari2 </a>

**Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo**
------- | --- | ------- 
09:00|15|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#marcoc">Marco2 Calamari2 </a><br/><em>«IA: Tecnologia, Etica e Privacy»</em></span>
09:15|15|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#valiani">Lisa Valiani (Federazione Ordini degli Ingegneri della Toscana)</a><br/><em>Saluti Istituzionali</em></span>
09:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#ciurcina">Marco Ciurcina (StudioLegale.it)</a><br/><em><a name='1m01'></a><a href="/e-privacy-XXXII-interventi.html#ciurcina">Politiche per la ricerca scientifica sull'IA</a></em></span>
10:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#mastella">Stefano Mastella </a>, <a href="/e-privacy-XXXII-relatori.html#quirox">Quiroz Marco (Università degli Studi di Milano)</a> e <a href="/e-privacy-XXXII-relatori.html#giacomello">Jolanda Giacomello </a><br/><em><a name='1m02'></a><a href="/e-privacy-XXXII-interventi.html#mastella">Associazionismo e libertà: strumenti giuridici, etici e tecnici per la partecipazione libera e protetta</a></em></span>
10:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#aterno">Stefano Aterno (Studio Legale E-LEx)</a><br/><em><a name='1m03'></a><a href="/e-privacy-XXXII-interventi.html#aterno">La (in) sicurezza della IA</a></em></span>
11:00|30|<span class='talk'><em>Pausa</em></span>
11:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#berto">Rebecca Berto </a><br/><em><a name='1m04'></a><a href="/e-privacy-XXXII-interventi.html#berto">Intelligenza artificiale,  discriminazione e normativa europea</a></em></span>
12:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#patriarca">Paola Patriarca </a><br/><em><a name='1m05'></a><a href="/e-privacy-XXXII-interventi.html#patriarca">Smart city e innovazione: una nuova sfida per i diritti individuali e la sicurezza dei cittadini</a></em></span>
12:30|60|<span class='talk'>Modera: <a href="/e-privacy-XXXII-relatori.html#marcoc">Marco2 Calamari2 </a><br/>Partecipano: <a href="/e-privacy-XXXII-relatori.html#ciurcina">Marco Ciurcina (StudioLegale.it)</a><br/><em><a name='1m07'></a><a href="/e-privacy-XXXII-interventi.html#tavola1">talk-def-not-found(tavola1)</a></em></span>
13:30||<span class='talk'><em>Chiusura sessione</em></span>

#### <a name="vep"></a>Giovedì 23 novembre 2023 - pomeriggio

<!-- iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/lvZEosz11yE" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe -->

* Modera: <a href="/e-privacy-XXXII-relatori.html#berto">Rebecca Berto </a>

**Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo**
------- | --- | ------- 
15:00|5|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#berto">Rebecca Berto </a><br/><em>Apertura sessione pomeridiana</em></span>
15:05|25|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#scorza">Guido Scorza (Garante Privacy)</a><br/><em><a name='1p01'></a><a href="/e-privacy-XXXII-interventi.html#scorza">Il Garante e l'IA</a></em></span>
15:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#menendez">Natalia Menéndez González (Istituto Universitario Europeo)</a><br/><em><a name='1p02'></a><a href="/e-privacy-XXXII-interventi.html#menendez">Da un grande potere derivano grandi responsabilità: proporzionalità nell'uso della tecnologia di riconoscimento facciale</a></em></span>
16:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#vescovi">Chiara Vescovi (Università Milano-Bicocca e ReD OPEN)</a><br/><em><a name='1p03'></a><a href="/e-privacy-XXXII-interventi.html#vescovi">Dal principio precauzionale all'approccio consapevole: la sfida dell'autovalutazione per l'AI</a></em></span>
16:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#matteuzzi">costanza matteuzzi (Costituenda Associazione NO.VIO)</a><br/><em><a name='1p04'></a><a href="/e-privacy-XXXII-interventi.html#matteuzzi1">Email. Uno strumento obsoleto?</a></em></span>
17:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#giorio">Diego GIORIO (Sepel Editrice)</a><br/><em><a name='1p05'></a><a href="/e-privacy-XXXII-interventi.html#giorio">Se l'AI fosse la soluzione e non il problema? Almeno nella Pubblica Amministrazione</a></em></span>
17:30||<span class='talk'><em>Chiusura sessione</em></span>

#### <a name="sam"></a>Venerdì 24 novembre 2023 - mattina

<!-- iframe width="560" height="315" src="https://www.youtube-nocookie.com/embed/9UIuEWuVobk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe -->


* Modera: <a href="/e-privacy-XXXII-relatori.html#giorio">Diego GIORIO (Sepel Editrice)</a>

 **Ora** | Durata | **Relatore**&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <br/> **Titolo** 
------- | --- | ------- 
09:30|5|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#giorio">Diego GIORIO (Sepel Editrice)</a><br/><em>Apertura seconda giornata</em></span>
09:35|25|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#matteuzzi">costanza matteuzzi (Costituenda Associazione NO.VIO)</a><br/><em><a name='2m01'></a><a href="/e-privacy-XXXII-interventi.html#matteuzzi2">l'oblio e il giornalismo d'inchiesta</a></em></span>
10:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#pievatolo">curriculum-not-found(pievatolo)  </a><br/><em><a name='2m02'></a><a href="/e-privacy-XXXII-interventi.html#pievatolo">Dati privati e felicità pubblica</a></em></span>
10:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#landucci">Luca Landucci (Pro Cultura Aperta)</a><br/><em><a name='2m03'></a><a href="/e-privacy-XXXII-interventi.html#landucci">Iil futuro dell'algoritmo pubblicitario e la protezione della privacy</a></em></span>
11:00|30|<span class='talk'><em>Pausa</em></span>
11:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#bassoli">Elena Bassoli (Angif (Ass. Naz. Giuristi e Informatici e Forenser))</a><br/><em><a name='2m04'></a><a href="/e-privacy-XXXII-interventi.html#bassoli">Il Machine learning nel nuovo “Regolamento Macchine”</a></em></span>
12:00|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#vieri">giovambattista Vieri (consulente it)</a><br/><em><a name='2m05'></a><a href="/e-privacy-XXXII-interventi.html#vieri">Io non ho nulla da nascodere, che mi importa della sicurezza IT?</a></em></span>
12:30|30|<span class='talk'><a href="/e-privacy-XXXII-relatori.html#brambilla">curriculum-not-found(brambilla)  </a><br/><em><a name='2m06'></a><a href="/e-privacy-XXXII-interventi.html#brambilla">Antropologia del transumanesimo: una risposta critica</a></em></span>
13:00||<span class='talk'><em>Chiusura sessione</em></span>



## <a name="talks"></a>Gli interventi

#### <a name="aterno"></a> La (in) sicurezza della IA<a href="/e-privacy-XXXII-programma.html#1m03">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#aterno">Stefano Aterno (Studio Legale E-LEx)</a>*

L'IA e le altre tecnologie emergenti (come i computer quantistici) sembrano spingere gli esseri umani verso una conoscenza della realtà che va oltre i confini della loro stessa percezione.&#13;&#10;Ma queste tecnologie hanno dei limiti. A fronte di grandi vantaggi già oggi  evidenti (e in futuro ancora più sbalorditivi) preoccupano a ragione i rischi, le incertezza e le insicurezze che l'uso di tali tecnologie comporteranno. Ci interroghiamo a livello mondiale sugli effetti, sulle criticità, sui danni, sulle responsabilità che l'uso di tale tecnologia comporterà. Il nostro problema è che non riusciamo ancora ad afferrare le implicazioni filosofiche del nostro rapporto con tali tecnologie. Stiamo progredendo in modo automatico e non cosciente. E questo è un problema. Stiamo assistendo ad un cambiamento della coscienza umana. Durante l'illuminismo la coscienza umana subì una trasformazione perchè la stampa (la nuova tecnologia dell'epoca) aveva prodotto nuove intuizioni filosofiche che erano state diffuse a loro volta dalla stessa tecnologia. Oggi si sta sviluppando una nuova tecnologia che però non solo è priva delle regole tecniche scritte tipiche delle grandi invenzioni, ma è ancora priva di una filosofia capace di guidarla. Dobbiamo quindi affrontare la sfida di sviluppare una visione etica e filosofica per guidare l'uso di queste potenti tecnologie, in modo da massimizzare i benefici e mitigare i rischi. È necessario un approccio multidisciplinare che coinvolga filosofi, scienziati, responsabili delle politiche, sviluppatori e la società nel suo complesso. Solo attraverso un dibattito approfondito e una guida filosofica adeguata possiamo affrontare responsabilmente la rapida evoluzione di queste tecnologie e plasmare un futuro in cui esse siano in sintonia con i valori umani e contribuiscano al progresso sostenibile della società.&#13;&#10;Nonostante queste preoccupazioni e insicurezze, è importante sottolineare che l'IA e le tecnologie emergenti hanno il potenziale di portare notevoli vantaggi alla società. Ad esempio, possono migliorare l'efficienza operativa, facilitare la diagnosi e il trattamento delle malattie, ottimizzare le risorse energetiche e consentire nuove scoperte scientifiche. È fondamentale bilanciare attentamente i benefici con i rischi, lavorando per creare un ambiente in cui l'IA sia sviluppata in modo sicuro, transparente ed etico.&#13;&#10;&#13;&#10;&#13;&#10;In conclusione, l'IA e le tecnologie emergenti costituiscono una doppia sfida: da un lato, presentano un vasto potenziale che può superare le limitazioni della nostra percezione e conoscenza; dall'altro, sorgono preoccupazioni riguardo ai rischi, alle incertezze e alle insicurezze che possiamo affrontare se queste tecnologie non sono gestite in modo adeguato. Per affrontare tali sfide, è necessario adottare un approccio responsabile basato su una solida base etica e filosofica, coinvolgendo diverse parti interessate per sviluppare un quadro normativo e regolamentare che favorisca lo sviluppo sicuro, responsabile ed equo delle tecnologie emergenti.&#13;&#10;


#### <a name="bassoli"></a> Il Machine learning nel nuovo “Regolamento Macchine”<a href="/e-privacy-XXXII-programma.html#2m04">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#bassoli">Elena Bassoli (Angif (Ass. Naz. Giuristi e Informatici e Forenser))</a>*

Tra le novità più rilevanti del nuovo Regolamento Macchine del 2023 vi è un approccio particolare alle componenti digitali, compreso il software, che viene per la prima volta introdotto nella disciplina macchine e l’introduzione di nuove responsabilità per fornitori, importatori e distributori con specifico riguardo al “comportamento autoevolutivo” delle macchine in cui sia stato implementato un qualche tipo di machine learning.&#13;&#10;Ciò determinerà particolari obblighi in capo agli operatori economici, in particolare per quanto attiene alla valutazione dei rischi e all’obbligo di introduzione di “limitatori di apprendimento”, come prescritto dal nuovo Regolamento, oltre alla messa a disposizione del codice sorgente o della logica di programmazione del software relativo alla sicurezza al fine di dimostrare la conformità della macchina o del prodotto correlato rispetto al Regolamento a seguito di richiesta da parte di un’Autorità nazionale.&#13;&#10;


#### <a name="berto"></a> Intelligenza artificiale,  discriminazione e normativa europea<a href="/e-privacy-XXXII-programma.html#1m04">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#berto">Rebecca Berto </a>*

“Poca favilla gran fiamma seconda” (Paradiso I, 34) scrisse Dante in un invito ai posteri a seguire il richiamo universale dei perenni valori umani. &#13;&#10;L'invenzione di tecnologie sempre più efficienti e di largo utilizzo pongono già adesso quesiti giuridici rilevanti: per esempio, le difficoltá connesse a dimostrare che una decisione avente effetti giuridici rilevanti sulla singola persona sia stata adottata solamente da un algoritmo.&#13;&#10;&#13;&#10;Difficoltá emergono anche nel riuscire ad applicare il principio di non-discriminazione in ambito tecnologico. Difatti uno dei temi che desta maggiore preoccupazione è che le applicazioni dell'Intellingenza Artificiale possa portare a pratiche discriminatorie: fra queste quelle che pongono maggiori complicazioni sono quelle pratiche apparentemente neutrali, ma discriminatorie ad un'analisi più attenta. Con la conseguenza che le potenziali vittime nemmeno si accorgono di essere state svantaggiate e non possono porvi rimedio.&#13;&#10;&#13;&#10;La normativa europea, pur ribadendo, in vari livelli normativi, il principio di non-discriminazione, lascia aperte delle criticità.&#13;&#10;


#### <a name="brambilla"></a> Antropologia del transumanesimo: una risposta critica<a href="/e-privacy-XXXII-programma.html#2m06">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#brambilla">curriculum-not-found(brambilla)  </a>*

Il concetto di progresso occupa un posto chiave nel modo in cui l’uomo intende la tecnologia, sebbene non vada sempre di pari passo con il bene morale. L’articolo, dopo aver brevemente presentato il concetto di progresso tecnologico e il suo stato attuale, si concentra sulla concezione dell’antropologia e della tecnica che emergono dal transumanesimo. In particolare, esamina l’interpretazione del corpo umano e i tre passaggi che Nick Bostrom indica come indispensabili per raggiungere il proprio sé transumano. In seguito, delinea i concetti di piacere e felicità, esplicitando che il sostrato filosofico da cui sono tratti è l’utilitarismo di matrice edonista nella versione di John Stuart Mill. Infine, propone una critica del transumanesimo con lo scopo di evidenziarne le contraddizioni che lo affliggono circa il concetto di natura umana e piacere, opponendo una visione differente dell’uomo e della felicità, grazie agli scritti di Aristotele e Tommaso d’Aquino. &#13;&#10;&#13;&#10;


#### <a name="ciurcina"></a> Politiche per la ricerca scientifica sull'IA<a href="/e-privacy-XXXII-programma.html#1m01">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#ciurcina">Marco Ciurcina (StudioLegale.it)</a>*

Si illustrano il contesto tecnologico e normativo che, con opportune scelte politiche, potrebbero favorire la libera disponibilità, lo studio e la comprensione dei sistemi d’intelligenza artificiale.&#13;&#10;Per conseguire questo fine, è utile valorizzare i metodi già adottati per il software libero. &#13;&#10;È anche utile approfittare del quadro normativo europeo che permette di adottare politiche che valorizzano la ricerca scientifica nello sviluppo dei sistemi d’intelligenza artificiale.


#### <a name="giorio"></a> Se l'AI fosse la soluzione e non il problema? Almeno nella Pubblica Amministrazione<a href="/e-privacy-XXXII-programma.html#1p05">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#giorio">Diego GIORIO (Sepel Editrice)</a>*

Anche se non mancano casi di scarsa digitalizzazione anche nel settore privato, la Pubblica Amministrazione ha la nomea, a torto o ragione, di procedere come nell'800, gestendo gli iter con faldoni, timbri, montagne di moduli da compilare in triplice copia. L'accumulo di carta implica spesso la saturazione degli archivi, per cui i faldoni cominciano ad accumularsi nei corridoi accessibili al pubblico, o restare visibili sulle scrivanie. Anche la digitalizzazione non è esente da scarsa consapevolezza o attenzione alla sicurezza, amplificando la magnitudo del data breach in caso di perdita dei dati. Se quindi l'apparto pubblico ha poche risorse per la formazione e la gestione dei sistemi, un'AI attentamente programmata e controllata centralmente potrebbe essere una soluzione, anziché un problema?


#### <a name="landucci"></a> Iil futuro dell'algoritmo pubblicitario e la protezione della privacy<a href="/e-privacy-XXXII-programma.html#2m03">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#landucci">Luca Landucci (Pro Cultura Aperta)</a>*

Esploreremo la connessione tra l'Intelligenza Artificiale e il futuro del targeting pubblicitario, ponendo particolare enfasi sulla protezione della privacy dei consumatori. L'utilizzo dell'IA nella progettazione di algoritmi pubblicitari è in continua evoluzione, mentre le aziende cercano di trovare un equilibrio tra la fornitura di contenuti pubblicitari rilevanti e il rispetto della privacy degli utenti.


#### <a name="mastella"></a> Associazionismo e libertà: strumenti giuridici, etici e tecnici per la partecipazione libera e protetta<a href="/e-privacy-XXXII-programma.html#1m02">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#mastella">Stefano Mastella </a>, <a href="/e-privacy-XXXII-relatori.html#quirox">Quiroz Marco (Università degli Studi di Milano)</a> e <a href="/e-privacy-XXXII-relatori.html#giacomello">Jolanda Giacomello </a>*

La velocità del cambiamento tecnologico tende a stimolare una iper-produzione normativa ed un cambiamento incessante della disciplina sulla riservatezza. in Europa, per esempio, dove le direttive prima ed il GDPR poi hanno uniformato e generalizzato la disciplina del trattamento dei dati personali le leggi sono continuamente modificate per adeguarle alle nuove minacce alla riservatezza o sono adattate alle concorrenti esigenze di informazione, comunicazione e commercio. Negli Stati Uniti le esigenze di tutela della privacy hanno determinato il fiorire di una vasta legislazione speciale (la privacy dei guidatori, la privacy dei lettori, dei consumatori, dei bambini, ecc) a tal punto che è oggettivamente difficile districarsi nella congerie di strumenti normativi federali, statali e frutto dell’autonomia privata. Velocità del cambiamento e accumulo normativo non vanno certo nella direzione del rafforzamento e della maggiore protezione dell’autonomia individuale: la cornice si fa confusa e l’individuo è esposto all’incertezza ed al peso delle influenze esterne. La moltiplicazione e la specificazione del diritto alla privacy ha creato occasioni di conflitto non solo tra il diritto alla riservatezza ed altri diritti di pari rilievo giuridico (libertà di informazione, trasparenza amministrativa etc..) ma ha ingenerato conflitti interni tra attori sociali diversi in nome dello stesso diritto alla riservatezza. La più grave conseguenza non prevista e non voluta dell’affermarsi del diritto alla riservatezza si è, tuttavia manifestata in Europa ed i contorni della sua gravità non sono ancora del tutto stati compresi e consistono nell’aumento del potere discrezionale delle autorità di regolazione del settore del trattamenti dei dati personali nel vecchio Continente, non controbilanciato da un aumento della possibilità per i cittadini europei di partecipare alle decisioni né con strumenti di democrazia rappresentativa né tanto meno con forme di democrazia deliberativa.&#13;&#10;&#13;&#10;Essenziale, dunque, il tema della sovranità riferita non solo e non tanto all’individuo come singolo ma come soggetto che opera politicamente mediante le formazioni sociali in cui è inserito.&#13;&#10;&#13;&#10;Il tema è trasversale e comporta la garanzia per il soggetto di sceglie se condividere le proprie opinioni, valutazioni scelte o preferenze all’interno di un gruppo circoscritto (l’associazione, il gruppo, il coordinamento) e se e come manifestare anche all’esterno le scelte e le opinioni individuali e collettive. Il tema non è quindi affrontabile senza un approfondimento sotto il profilo tecnologico di come di come occultare o disoccultare consapevolmente la propria presenza su internet e sui mezzi digitali, da un lato, e di come al potere delle autorità di controllo (governance dei fenomeni) può contrapporsi un potere di autoregolazione (poietico, pratico) che spetta agli individui ed alle associazioni.&#13;&#10;&#13;&#10;Produzione e controllo, trasformazione ed autoregolazione nell’era digitano pongono nuove sfide che solo un approccio interdisciplinare può affrontare nell’ottica del rafforzamento della capacità di partecipazione alle scelte politiche.&#13;&#10;&#13;&#10;L’intervento sarà diviso in tre “atti”. Il primo atto prevede un breve excursus sui sistemi giuridici pensati per proteggere l’autonomia individuale e nelle interazioni sociali. Il secondo atto prevede la definizione delle implicazioni etiche della determinazione della libertà di decidere di essere ciberneta (di guidare la propria barca in condizioni avverse). Il terzo atto esplora gli strumenti per permettere agli individui e ai gruppi di esprimersi liberamente al di là del controllo del potere.&#13;&#10;


#### <a name="matteuzzi1"></a> Email. Uno strumento obsoleto?<a href="/e-privacy-XXXII-programma.html#1p04">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#matteuzzi">costanza matteuzzi (Costituenda Associazione NO.VIO)</a>*

la email è uno degli strumenti più utilizzati nelle relazioni quotidiane. tuttavia questo strumento ha delle importanti criticità. Pertanto occorre domandarsi quali sono e se vi sono strumenti alternativi. I relatori intendono utilizzare sia un approccio giuridico che informatico, mettendo in evidenza i problemi di riservatezza e tutela dei dati che la mail ha. Inoltre si indicheranno delle alternative e se esistono dei sistemi mail più sicuri.


#### <a name="matteuzzi2"></a> l'oblio e il giornalismo d'inchiesta<a href="/e-privacy-XXXII-programma.html#2m01">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#matteuzzi">costanza matteuzzi (Costituenda Associazione NO.VIO)</a>*

Ci sono state importanti novità normative molto recenti. Dal 1° gennaio 2023, per legge gli imputati che sono stati assolti o in seguito all'archiviazione del loro caso in un procedimento penale hanno diritto alla cancellazione del proprio nominativo dai motori di ricerca. L'oblio dunque riguarda sia la data protection, ma anche la tutela dei diritti fondamentali. A questo punto ci si interroga sul tema del giornalismo d'inchiesta che ha delle peculiarità in tema di oblio. Si portano dei casi pratici per cercare di spiegare il difficile bilanciamento tra il compimento di alcuni reati particolarmente gravi (mafia o terrorismo) e oblio.


#### <a name="menendez"></a> Da un grande potere derivano grandi responsabilità: proporzionalità nell'uso della tecnologia di riconoscimento facciale<a href="/e-privacy-XXXII-programma.html#1p02">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#menendez">Natalia Menéndez González (Istituto Universitario Europeo)</a>*

La relazione discuterà l’'applicazione del principio di proporzionalità nell'uso delle Tecnologie di Riconoscimento Facciale (TRF). In particolare, approfondirà il modo con cui le autorità di controllo (autorità di protezione dei dati personali) in tutta l’'Unione Europea hanno applicato tale principio in alcuni degli usi più controversi delle TRF su cui hanno avuto modo di pronunciarsi.


#### <a name="patriarca"></a> Smart city e innovazione: una nuova sfida per i diritti individuali e la sicurezza dei cittadini<a href="/e-privacy-XXXII-programma.html#1m05">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#patriarca">Paola Patriarca </a>*

Nel 2012 l’Istituto Treccani ha definito con il neologismo smart city “una città caratterizzata dall’integrazione tra saperi, strutture e mezzi tecnologicamente avanzati, propri della società della comunicazione e dell’informazione, finalizzati a una crescita sostenibile e al miglioramento della qualità della vita”. &#13;&#10;Tuttavia, il termine smart city ha guadagnato maggiore attenzione soltanto negli ultimi anni, grazie ad un progresso tecnologico rapido ed incessante che ha aperto la strada a molteplici scenari innovativi. La città intelligente rappresenta un ambizioso progetto che si fonda su un'alleanza vincente tra tecnologia e capitale umano intellettuale, politico e sociale. &#13;&#10;Smart city significa, tra le altre, un’organizzazione cittadina più interattiva e reattiva, spazi pubblici più sicuri e un migliore soddisfacimento delle esigenze di una popolazione: si pensi alla gestione del flusso del traffico tramite semafori intelligenti, alle reti di trasporto urbano più efficienti, alle nuove stazioni telefoniche intelligenti, fino ai processi innovativi per illuminare e riscaldare gli edifici e rendere più efficiente lo smaltimento dei rifiuti. &#13;&#10;Una city “domotica’’, interconnessa con una moltitudine di dispositivi collegati tra loro e al servizio dei cittadini, al fine di migliorare i servizi pubblici e la partecipazione dei consociati alla vita collettiva della città. &#13;&#10;Una smart city è in grado di analizzare esattamente le esigenze dei propri abitanti, conosce esattamente le loro abitudini perché si aggiorna continuamente sui loro spostamenti, sa cosa e quanto consumano e individua i servizi di cui hanno bisogno. Ma questo comporta grosse criticità sotto il profilo del trattamento dei dati. &#13;&#10;La costruzione di città intelligenti attribuisce infatti un’importanza centrale agli  aspetti legati alla sicurezza e alla sostenibilità, riconoscendo particolare attenzione alla raccolta, condivisione e conservazione dei dati personali dei singoli cittadini. Nelle città intelligenti, il ricorso massiccio alle tecnologie IoT genera incessantemente un'enorme quantità di dati, analizzati per fornire servizi innovativi ai cittadini. Nella corretta implementazione di queste tecnologie, una delle sfide maggiori riguarda proprio la tutela della riservatezza dei cittadini e la sicurezza delle loro informazioni, senza le quali mancherebbe la fiducia e l’appoggio dei consociati, la cui partecipazione è essenziale affinché si concretizzino i vantaggi legati allo sviluppo delle smart cities. &#13;&#10;Città di tutto il mondo si stanno adoperando per realizzare questa strategia di pianificazione urbanistica innovativa e all'avanguardia che chiama in causa attori politici, provider, esperti ma, soprattutto, gli stessi cittadini. &#13;&#10;Quali saranno gli scenari del prossimo futuro? Soprattutto, quali i rischi paventati rispetto allo sviluppo delle città intelligenti? L’intervento avrà lo scopo di illustrare questi aspetti, attraverso un’attenta analisi sulle criticità e sulle opportunità che la smart city offre, alla luce del quadro normativo nazionale ed europeo. &#13;&#10;


#### <a name="pievatolo"></a> Dati privati e felicità pubblica<a href="/e-privacy-XXXII-programma.html#2m02">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#pievatolo">curriculum-not-found(pievatolo)  </a>*

Stati e monopolisti dell'ICT usano i dati personali per progetti che giustificano con lo scopo di una presunta felicità collettiva. E lo possono fare senza troppe difficoltà, anche dove esistono legislazioni a tutela della privacy, quando i dati personali sono trattati come proprietà, (a) virtualmente esclusivi ma alienabili, specialmente ove i monopolisti propongono termini di servizio come offerte che non si possono rifiutare, e (b) limitati all'interesse individuale, anche qualora i "proprietari" fossero consapevoli che il carattere panottico dell'ordine sociale è un problema collettivo. Winston in "1984" viene riassimilato al sistema perché le azioni politiche collettive sono al di là della sua portata - perfino l'opposizione è organizzata dallo stato - e si trova a difendere solo un precario e infine illusorio fortino privato individuale.  É possibile intendere la condivisione - o no - dei dati personali come una questione di azione e di politica collettiva? Proverò a rispondere a questa domanda a partire dalle riflessione di Kant sul rapporto fra felicità e politica.&#13;&#10;


#### <a name="scorza"></a> Il Garante e l'IA<a href="/e-privacy-XXXII-programma.html#1p01">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#scorza">Guido Scorza (Garante Privacy)</a>*




#### <a name="vescovi"></a> Dal principio precauzionale all'approccio consapevole: la sfida dell'autovalutazione per l'AI<a href="/e-privacy-XXXII-programma.html#1p03">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#vescovi">Chiara Vescovi (Università Milano-Bicocca e ReD OPEN)</a>*

Nell'ambito dell'Intelligenza Artificiale, l'emergente e vasta complessità normativa anticipa l'avvento di regolamentazioni più rigorose. Tuttavia, l'etica, che si riflette in ogni normativa, è intrinsecamente legata alla cultura di una certa società. Pertanto, gli strumenti sviluppati per navigare in questa complessità devono essere profondamente radicati nel contesto socio-culturale in cui operano. Questa esigenza diventa ancor più evidente quando si esplora il concetto di responsabilità, oscillando tra le prescrizioni del GDPR e le nuove proposte normative emergenti. La chiave per affrontare questi rapidi cambiamenti risiede nella creazione di strumenti che non solo aumentino la coscienza decisionale, ma che conservino anche la flessibilità necessaria per adattarsi all'evoluzione continua delle tecnologie AI. La direzione ottimale combina principi solidi con interventi specifici di governance e organizzazione. Uno strumento particolarmente efficace in questo contesto è l'introduzione di un momento "ex ante", un punto di autovalutazione che fornisce gli elementi essenziali per navigare il panorama normativo con chiarezza e consapevolezza.


#### <a name="vieri"></a> Io non ho nulla da nascodere, che mi importa della sicurezza IT?<a href="/e-privacy-XXXII-programma.html#2m05">⇧</a>
*<a href="/e-privacy-XXXII-relatori.html#vieri">giovambattista Vieri (consulente it)</a>*

Io non ho nulla da nascodere, che mi importa della sicurezza IT?&#13;&#10;Quante volte abbiamo sentito dire questo ? Forse e' il caso di cambiare ottica e cominciare a scoprire cosa e quanto queste attitudinin possono donare alla societa' e, ai suoi stakeholder.&#13;&#10;&#13;&#10;Cominciamo a parlare di tracce digitali rilevabili liberamente in molti paesi con un hardware da meno di 50 euro escluso pc.&#13;&#10;&#13;&#10;Di certo avete usato i dongle tv sul pc. E quelli bluetooh. E altri ancora (Zigbee? Lora?). Spesso questi apparati operano su frequenze ad ascolto libero e, il cui ascolto e' addirittura possibile da remoto, via web. Ma cosa troviamo su queste frequenze ? Sicuramente lettori di temperatura, pioggia e umidita'. Sensori a contatto. Pressione e temperatura delle gomme, contabilizzatori e altro ancora. Ricordo a tutti del bluetooth e del suo MAC facilmente registrabile... Insomma cosine molto interessanti che visto che usiamo rigorsamente in chiaro, e non ci diamo pena di cio' forse, nazioni, comuni e cittadini dovrebbero cominciare a usare. Mi raccomando senza mai violare la legge. Che al riguardo e' permissiva e chiara.&#13;&#10;&#13;&#10;Ora, se aggiungiamo questo 'strumento' che puo' arrivare a decine di metri, alla&#13;&#10; biometria potremmo avere un riconoscimento biometro rafforzato e rilassato ? Ai&#13;&#10; posteri l'ardua sentenza.&#13;&#10;




## <a name="speakers"></a>I moderatori


### <a name='berto'></a>Rebecca Berto

Rebecca Berto è attiva come consulente legale in un progetto europeo
finanziato anche dalla Commissione Europea. Ha mosso i primi passi
lavorativi in ambito legale in uno studio legale della Corte d'Appello
di Trento. Poi gli eventi l'hanno portata prima a lavorare per
un'azienda a partecipazione pubblica e poi all'interno dell'attuale
progetto europeo. Ha continuato a studiare, specializzandosi in
risoluzione internazionale delle dispute commerciali, in altre parole
arbitrati commerciali internazionali e dispute internazionali relativi
ad investimenti: per questo motivo procedure come quelle previste dal
WTO o ICSID sono conosciute. Se volete chiederle dell'Energy Charter
Treaty e dei casi più recenti ve ne parlerà per ore! Nata a Celle, in
Germania, vive e lavora in Trentino Alto Adige. Pensa e parla in
italiano ed in tedesco, parla e pensa anche in inglese... ogni tanto
dice qualche frase in altre lingue straniere: cerca di studiarle di
più, fra un’attività ed un’altra. Ha la passione per le scienze
naturali, la fisica e le nuove tecnologie.

### <a name='calamari'></a> Marco Calamari (Progetto Winston Smith)

Marco Calamari. Ingegnere, classe 1955, talvolta noto come Cassandra,
a 18 anni dovette decidere se comprarsi una macchina usata od un
pc. Scelse il pc e da allora non si e' ancora completamente ripreso.
Lavora come archeologo di software legacy in una grande
multinazionale, ma e' appassionato di privacy e crittografia in Rete,
dove collabora a progetti di software libero come Freenet, Mixmaster,
Mixminion, Tor & GlobaLaks.

E' il fondatore del Progetto Winston Smith e tra i fondatori
dell'associazione Hermes Centro Studi Trasparenza e Diritti Umani Digitali.  
Dal 2002 organizza il convegno "e-privacy" dedicato alla
privacy in Rete e fuori, ed e' editorialista di "Punto Informatico"
dove pubblica la rubrica settimanale 
<a href="http://punto-informatico.it/cerca.aspx?s=cassandra%20calamari&t=4">"Cassandra Crossing"</a>.

### <a name='giorio'></a>Diego Giorio  (Progetto Winston Smith)

Dopo un'esperienza nell'industria privata, nella ricerca&sviluppo di
una multinazionale di seminconduttori prima, nel marketing e nel web
marketing poi, ho successivamente avuto altre esperienza professionali
prima di approdare alla Pubblica Amministrazione, nei servizi
demografici di un piccolo Comune. Dal 2009 ho iniziato a pubblicare
con SEPEL articoli in varie materie demografiche e di interesse
generale della PA, ho tenuto corsi di formazione per un'Associazione
di settore, dopo avere ottenuto il titolo di formatore dal Ministero
dell'Interno. Fra i vari interessi, la privacy ed il suo impatto sulla
PA, e dal 2012 seguo il convegno e-privacy, sia come uditore che come
relatore.


### <a name='priolo'></a>Enrica Priolo (Bonadio Priolo LTF )

Senior partner dello studio legale Bonadio Priolo LTF, sono avvocata
(di estrazione penalista) e formatrice, specializzata in diritti umani
e in legal tech. Le mie aree di ricerca sono principalmente la
privacy, l'intelligenza Artificiale, i processi decisionali
automatizzati e l'ethics by design; il mio approccio al diritto è di
tipo filosofico. Sono co-founder dell'associazione Legal Hackers Pisa.


### <a name='somma'></a>Emmanuele Somma  (Progetto Winston Smith)

Emmanuele Somma è prestato da anni al Progetto Winston Smith. È giornalista
pubblicista, ha fondato Linux Magazine e dirige "LOGIN, saving the
Internet wealth". 
## <a name="speakers"></a>I relatori

#### <a name="aterno"></a> Stefano Aterno (Studio Legale E-LEx)

Avvocato, Cassazionista, professore universitario



#### <a name="bassoli"></a> Elena Bassoli (Angif (Ass. Naz. Giuristi, Informatici e Forenser))

Titolare dello Studio legale Bassoli, si occupa dal 1995 prevalentemente di privacy, diritto all'oblio,  legal cybersecurity, computer crimes, tutela della proprietà industriale, e intellettuale, contratti informatici, digital evidence, algoritmica giuridica. &#13;&#10;Docente di Diritto della comunicazione elettronica e di Cyber Security and Data Protection Università degli Studi di Genova. &#13;&#10;Presidente di ANGIF (Associazione Nazionale Giuristi Informatici e Forensi).&#13;&#10;Autore di oltre 300 pubblicazioni in materia.



#### <a name="marcoc"></a> Marco2 Calamari2 

Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego Il mio alter-ego



#### <a name="ciurcina"></a> Marco Ciurcina (StudioLegale.it)

Avvocato in Torino, opera nel campo del diritto commerciale e contrattuale, diritto dell'Information Technology, diritto d'autore, brevetti e marchi, in particolare con focus su software libero, contenuti e dati aperti.&#13;&#10;Docente in "Diritto ed etica della comunicazione" presso il Politecnico di Torino.&#13;&#10;Attivamente impegnato per la promozione del software libero e dei diritti fondamentali nel digitale.



#### <a name="giacomello"></a> Jolanda Giacomello 

Dopo gli Studi classici, e da sempre appassionata di temi etici, mi sono laureata in Filosofia presso l’Università degli Studi di Padova, approfondendo la filosofia morale e l’estetica.Appassionata alla filosofia aristotelica ho, inoltre, approfondito il pensiero di Tommaso d’Aquino e Jaques Maritain. Dal 2001 mi occupo di consulenza e formazione in ambito privacy e sicurezza dei dati personali. Nel 2020 ho conseguito un Master in Cybersecurity



#### <a name="landucci"></a> Luca Landucci (Pro Cultura Aperta)

Luca Landucci è un utente attivo su Wikipedia dal 2008 ed è anche un membro di Wikimedia Italia, di cui è stato parte del direttivo. Attualmente, ricopre la carica di presidente di Pro Cultura Aperta, un'associazione che si dedica alla promozione dei beni culturali, alla valorizzazione del patrimonio culturale e dei territori. Ha organizzato eventi in Toscana volti a promuovere città sfruttando gli strumenti open access. &#13;&#10;Il suo lavoro professionale si concentra sul digital marketing e sull'intelligenza artificiale.



#### <a name="quirox"></a> Quiroz Marco (Università degli Studi di Milano)

Dopo gli studi classici presso il liceo-ginnasio "G. Carducci" di Milano, nel 1992 mi sono laureato in giurisprudenza presso l'Università degli studidi Milano con votazione 110/110 e menzione di lode, discutendo una tesi di laurea in Sociologia del diritto dal titolo "Diritti degli emarginati ed istituzioni assistenziali. Studio sul Servizio di accoglienza Milanese", relatore Prof. V. Ferrari, correlatoreProf. M. Ghezzi. In tale primo studio veniva svolta una ricerca empirica di tipo socio giuridico sul rispetto dei diritti fondamentali dei soggetti marginali e come tali svantaggiati nelle interazioni con i servizi pubblici. Ho proseguito gli studi in camposociologico del diritto e della politica accedendo per concorso al dottorato di ricerca in Sociologia delle istituzioni giuridiche e politiche, sede amministrativa di Macerata sotto la supervisione del Prof. D. Nelken; durante il 1995, ho trascorso un periododi studio a Londra sotto la guida del Prof. M. Freeman, (University College of London), durante il quale ho approfondito la conoscenza dell'istituto dell'Ombudsman (Difensore civico), nei paesi di cultura anglosassone, studiando presso l’Institute of AdvancedLegal Studies di Londra. Nel 1998 ho conseguito il titolo accademico di Dottore di ricerca in Sociologia delle istituzioni giuridiche e politiche, rilasciato dal MIUR con una tesi dal titolo "Il controllo della discrezionalità amministrativa, forme partecipativee diritti dei cittadini". Nel 2001 ho frequentato il modulo “strumenti di analisi qualitativa: l’intervista in profondità e l’intervista narrativa” della Scuola di Metodologia della ricerca sociale presso la Facoltà di Sociologia dell’Università degli Studidi Milano – Bicocca.&#13;&#10;&#13;&#10;Negli anni successivi, pur esercitando la professione forense, ho continuato gli studi come assistente volontario presso l’Università degli studidi Milano e realizzato una intensa attività di ricerca che mi ha permesso la pubblicazione di monografie e di numerosi articoli presenti in riviste nazionali e internazionali. &#13;&#10;&#13;&#10; &#13;&#10;&#13;&#10; &#13;&#10;&#13;&#10;&#13;&#10;CARRIERA ACCADEMICA &#13;&#10;&#13;&#10;2021- &#13;&#10; &#13;&#10; &#13;&#10;&#13;&#10;Professore associato di Filosofia del diritto Università degli studi di Milano &#13;&#10; &#13;&#10;&#13;&#10;2018- &#13;&#10; &#13;&#10;Professore invitato presso L’Istituto universitario salesiano di Venezia, aggregato alla Pontificia universitàsalesiana di Roma&#13;&#10; &#13;&#10;&#13;&#10;2012-2020&#13;&#10; &#13;&#10;Professore aggregato di Filosofia del diritto Università degli studi di Milano&#13;&#10; &#13;&#10;&#13;&#10;2006-2012&#13;&#10; &#13;&#10;Ricercatore di Filosofia del diritto Università degli studi di Milano&#13;&#10; &#13;&#10;&#13;&#10;2004-2009 &#13;&#10; &#13;&#10;Professore a contratto / incaricato di Organizzazione aziendale, Università degli Studi di Bologna &#13;&#10; &#13;&#10;



#### <a name="mastella"></a> Stefano Mastella 

Ingegnere dell’informazione, master in secondo livello in Cybersecurity conseguito presso l’Università degli Studi di Milano. Si occupa di informatica da sempre e di sicurezza delle informazioni da poco. Consulente in ambito della protezione dei dati personali e della cybersecurity.



#### <a name="matteuzzi"></a> costanza matteuzzi (Costituenda Associazione NO.VIO)

Avvocato del Foro di Firenze. Specializzata in reati informatici. Data Protection e CyberSecurity Law. Si occupa sia di attività giudiziale che stragiudiziale su questi temi. Relatore per numerosi eventi su queste materie, autrice di articoli scientifici.



#### <a name="menendez"></a> Natalia Menéndez González (Istituto Universitario Europeo)

Natalia Menéndez González è dottoranda di ricerca presso l'Istituto Universitario Europeo dove ricerca sulla proporzionalità nell'uso della tecnologia di riconoscimento facciale.&#13;&#10;&#13;&#10;È inoltre assistente alla didattica presso la School of Transnational Governance, assegnista di ricerca presso il Centro di Diritto della Società dell'Informazione, co-fondatrice del blog The DigiCon, ricercatrice in visita presso il Biometrics Law Lab del Center for IT. & IP Law presso la Facoltà di Giurisprudenza e Criminologia della KU Leuven ed ex vicepresidente degli studenti di dottorato nel gruppo di ricerca AI Ethics. I suoi altri interessi di ricerca includono l'etica dell'intelligenza artificiale, in particolare per NLP e l'intersezione tra intelligenza artificiale e democrazia.



#### <a name="patriarca"></a> Paola Patriarca 

Junior Associate presso lo Studio Legale E-Lex, collaboro con esperti professionisti in materia di Data Protection, Amministrazione digitale, Proprietà intellettuale, Sicurezza informatica e Cybercrime e tutto ciò che riguarda le nuove sfide del digitale. Mi sono laureata in Giurisprudenza presso l’Università Federico II di Napoli con una tesi in Filosofia del Diritto dal titolo “La Giurisprudenza tra Interpretazione e Creazione del Diritto” approfondendo il tema dell’impatto dello sviluppo tecnologico sull'amministrazione della giustizia. Ormai fortemente appassionata al binomio diritto-tecnologia, ho conseguito un Master in Diritto delle Nuove Tecnologie e Informatica Giuridica presso l’Università Alma Mater Studiorum di Bologna con una tesi dal titolo "Reati informatici e Responsabilità amministrativa degli Enti". Nell'ultimo anno ho partecipato ad un Corso di Alta Formazione sui Diritti nel Metaverso. &#13;&#10;Fermamente convinta, quindi, dell’importanza e della centralità delle discipline che cercano di regolare una società ed un ambiente giuridico costantemente influenzato dall’utilizzo delle risorse digitali, mi piace e cerco di essere sempre aggiornata su questi temi.



#### <a name="scorza"></a> Guido Scorza (Garante Privacy)

Componente del Garante per la protezione dei dati personali Avvocato, giornalista pubblicista, professore a contratto di diritto delle nuove tecnologie. Già responsabile degli affari regolamentari del team per la trasformazione digitale della Presidenza del Consiglio dei Ministri e, poi, Consigliere giuridico del Ministro per l’innovazione. Insegna diritto delle nuove tecnologie presso l’Università europea, diritto dei contratti ad oggetto informatico presso il Master in informatica giuridica e diritto dell’informatica dell’Università degli Studi di Bologna e privacy nelle comunicazioni elettroniche presso il Master in protezione dei dati personali dell’Università Roma Tre. Ha fondato lo Studio ELex del quale è stato partner fino all’assunzione dell’incarico di componente del Collegio e l’Istituto per le politiche dell’innovazione dalla cui Presidenza si è egualmente dimesso a seguito dell’assunzione a componente del Collegio. È rappresentante vicario del Governo italiano presso il Government advisory Board dell’ICANN. È blogger su L’Espresso e Il Fatto Quotidiano e scrive su Mashable Italia, il Corriere delle Comunicazioni e Agendadgitale.eu. È autore di alcuni libri, gli ultimi dei quali sono “Processi al Futuro”, 2020 Egea e “Intelligenza artificiale. L’impatto sulle nostre vite, diritti e libertà”, 2020, con A. Longo, Mondadori. Prima ha, tra gli altri, scritto “Internet, i nostri diritti” con Anna Masera per Laterza e “Meglio se taci” con Alessandro Gilioli per Baldini&Castoldi.



#### <a name="vescovi"></a> Chiara Vescovi (Università Milano-Bicocca e ReD OPEN)

Chiara Vescovi è dottoranda in Informatica giuridica presso l'Università di Milano-Bicocca e Cyber Law Expert per ReD OPEN. Dopo alcune esperienze internazionali, tra cui uno stage all'INTERPOL di Lione, si è laureata in giurisprudenza con specializzazione in diritto Internazionale presso l'Università Bocconi di Milano. Dal 2021 è iscritta al dottorato di ricerca presso l'Università di Milano-Bicocca: una collaborazione tra l'Università e ReD OPEN. La sua ricerca indaga gli strumenti di governo dell'Intelligenza Artificiale, concentrandosi nello specifico sulle responsabilità connesse al suo utilizzo, soprattutto in ambito sanitario.



#### <a name="vieri"></a> giovambattista Vieri (consulente it)

Giovambattista Vieri, sono un figlio degli anni '60, sono appassionato di informatica da quando avevo 16 anni e con l'aiuto del saldatore modificavo lo spectrum. Ho poi lavorato nell'industria aerospaziale (project leader) sia su GUI sia su apparati embedded, passando poi a societa' di consulenza e formazione (responsabile gruppo internet), poi a societa' editoriali con ruoli anche inerenti la IT security. Infine imprenditore (molto piccolo) e consulente. Nei ritagli di tempo, scrivo software che poi libero . Son anche molto appassionato di Storia (antica e recente) e sport. Amo la cucina e la buona tavola condita da discussioni interessanti. E dimenticavo che istruisco i computer a ripetere i ns errori.






### Gli organizzatori

La manifestazione e’ organizzata da:

  - [Progetto Winston Smith](http://pws.winstonsmith.org/) è un’associazione senza fini di lucro che si occupa della difesa del diritto alla privacy in Rete e fuori
  - [HERMES](http://logioshermes.org/) \- Centro Studi Trasparenza e Diritti Umani Digitali.


### Contatti

Per contatti generali e per la
stampa: [eprivacy@winstonsmith.org](mailto:eprivacy@winstonsmith.org),
per i relatori
[cfp-eprivacy@winstonsmith.org](mailto:cfp-eprivacy@winstonsmith.org).

Maggiori informazioni saranno pubblicate sul sito del Convegno non appena
disponibili, all'indirizzo [e-privacy.winstonsmith.org](http://e-privacy.winstonsmith.org).

**Vi aspettiamo**.
